"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MÃ“DULO: PREPROCESAMIENTO DE DATOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PropÃ³sito: Transformar datos crudos en formato listo para LSTM

Funciones:
1. normalize_data() â†’ Escala temperaturas entre 0 y 1
2. create_sequences() â†’ Crea ventanas de tiempo para entrenar
3. split_train_test() â†’ Divide en entrenamiento y prueba
4. reshape_for_lstm() â†’ Da formato que LSTM necesita
5. save_scaler() / load_scaler() â†’ Guarda/carga el normalizador
"""

import numpy as np
from sklearn.preprocessing import MinMaxScaler
import pickle
from src.config import TIME_STEPS, TRAIN_SPLIT, SCALER_PATH


def normalize_data(data):
    """
    Normaliza los datos entre 0 y 1
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Â¿POR QUÃ‰ NORMALIZAR?
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Las redes neuronales funcionan mejor con nÃºmeros pequeÃ±os.
    Si usamos temperaturas directas (0Â°C - 26Â°C), el modelo
    aprende mÃ¡s lento y menos preciso.
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Â¿CÃ“MO FUNCIONA?
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    FÃ³rmula: valor_normalizado = (valor - mÃ­nimo) / (mÃ¡ximo - mÃ­nimo)
    
    Ejemplo:
    Temperatura: 13Â°C
    Rango: 0Â°C a 26Â°C
    Normalizado: (13 - 0) / (26 - 0) = 0.5
    
    Resultado: 13Â°C se convierte en 0.5
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Â¿QUÃ‰ ES MinMaxScaler?
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Es una herramienta de scikit-learn que:
    1. Calcula el mÃ­nimo y mÃ¡ximo de los datos
    2. Guarda estos valores (para revertir despuÃ©s)
    3. Aplica la fÃ³rmula de normalizaciÃ³n
    
    Args:
        data: Array con temperaturas originales
              Ejemplo: [[20.7], [17.9], [18.8], ...]
    
    Returns:
        tuple: (datos_normalizados, scaler)
               - datos_normalizados: Array con valores 0-1
               - scaler: Objeto que guarda min/max para revertir
    """
    # Crear el normalizador
    # feature_range=(0, 1) significa "escala entre 0 y 1"
    scaler = MinMaxScaler(feature_range=(0, 1))
    
    # fit_transform hace 2 cosas:
    # 1. fit: Aprende el mÃ­n y mÃ¡x de los datos
    # 2. transform: Aplica la normalizaciÃ³n
    scaled_data = scaler.fit_transform(data)
    
    # Mostrar informaciÃ³n
    print(f"âœ… Datos normalizados")
    print(f"   Original   â†’ min={data.min():.2f}Â°C, max={data.max():.2f}Â°C")
    print(f"   Normalizado â†’ min={scaled_data.min():.2f}, max={scaled_data.max():.2f}")
    print(f"   Ejemplo: {data[0][0]:.2f}Â°C â†’ {scaled_data[0][0]:.4f}")
    
    return scaled_data, scaler


def create_sequences(data, time_steps=TIME_STEPS):
    """
    Crea secuencias de tiempo para entrenar LSTM
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Â¿QUÃ‰ SON SECUENCIAS?
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    LSTM necesita "ventanas" de datos consecutivos.
    No le damos temperaturas sueltas, sino GRUPOS de dÃ­as.
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    EJEMPLO VISUAL
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Datos originales (10 dÃ­as):
    [20, 21, 19, 22, 23, 24, 22, 21, 20, 19]
    
    Con time_steps=3, creamos:
    
    Secuencia 1:  [20, 21, 19] â†’ Predice: 22
    Secuencia 2:  [21, 19, 22] â†’ Predice: 23
    Secuencia 3:  [19, 22, 23] â†’ Predice: 24
    Secuencia 4:  [22, 23, 24] â†’ Predice: 22
    ...
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Â¿POR QUÃ‰ time_steps=60?
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Usamos 60 dÃ­as (2 meses) porque:
    - Da suficiente contexto temporal
    - Captura patrones semanales y mensuales
    - No es tan largo que dificulte el entrenamiento
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PROCESO PASO A PASO
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    1. Recorremos los datos desde la posiciÃ³n 'time_steps'
    2. Para cada posiciÃ³n i:
       - X: toma los Ãºltimos time_steps dÃ­as (i-60 hasta i)
       - y: toma el dÃ­a actual (i)
    3. Guardamos cada par (X, y) para entrenar
    
    Args:
        data: Array normalizado de temperaturas
        time_steps: Cantidad de dÃ­as a usar como entrada
    
    Returns:
        tuple: (X, y)
               - X: Secuencias de entrada (3D)
               - y: Valores a predecir (1D)
    """
    X, y = [], []
    
    # Recorrer desde time_steps hasta el final
    # Â¿Por quÃ© desde time_steps? Porque necesitamos time_steps dÃ­as previos
    for i in range(time_steps, len(data)):
        # X: Ãºltimos time_steps dÃ­as
        # data[i-time_steps:i, 0] toma filas desde (i-60) hasta (i-1)
        # El :i no incluye i, por eso es "hasta i-1"
        X.append(data[i-time_steps:i, 0])
        
        # y: el dÃ­a actual (lo que queremos predecir)
        y.append(data[i, 0])
    
    # Convertir listas a arrays de NumPy (mÃ¡s eficiente)
    X, y = np.array(X), np.array(y)
    
    # Mostrar informaciÃ³n
    print(f"âœ… Secuencias creadas")
    print(f"   X shape: {X.shape} â†’ ({X.shape[0]} muestras, {X.shape[1]} dÃ­as)")
    print(f"   y shape: {y.shape} â†’ ({y.shape[0]} valores a predecir)")
    print(f"   LÃ³gica: Usar {time_steps} dÃ­as â†’ Predecir dÃ­a siguiente")
    print(f"   Total de ejemplos: {len(X)}")
    
    return X, y


def split_data(X, y, train_split=0.6, val_split=0.2):
    """
    Alias para split_train_val_test - Divide datos en 3 conjuntos: TRAIN, VALIDATION y TEST
    """
    return split_train_val_test(X, y, train_split, val_split)


def split_train_val_test(X, y, train_split=0.6, val_split=0.2):
    """
    Divide datos en 3 conjuntos: TRAIN, VALIDATION y TEST
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Â¿POR QUÃ‰ 3 CONJUNTOS?
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    AnalogÃ­a del estudiante:
    - TRAIN       = Ejercicios del libro (aprendes aquÃ­)
    - VALIDATION  = ExÃ¡menes de prÃ¡ctica (ajustas tu estudio)
    - TEST        = Examen final (evaluaciÃ³n honesta)
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    DIVISIÃ“N TEMPORAL (sin mezclar)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    |------ TRAIN (60%) ------|-- VAL (20%) --|-- TEST (20%) --|
    DÃ­as 1-2190              DÃ­as 2191-2920   DÃ­as 2921-3650
    
    IMPORTANTE: DivisiÃ³n cronolÃ³gica, NO aleatoria
    Â¿Por quÃ©? Queremos predecir el FUTURO, no el pasado.
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PROPÃ“SITO DE CADA CONJUNTO
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    1. TRAIN (60%):
       - AquÃ­ el modelo APRENDE patrones
       - Ajusta sus pesos internos
       
    2. VALIDATION (20%):
       - EvalÃºa el modelo DURANTE el entrenamiento
       - Detecta overfitting temprano
       - Ayuda a decidir cuÃ¡ndo parar (EarlyStopping)
       - El modelo NO entrena con estos datos
       
    3. TEST (20%):
       - EvaluaciÃ³n FINAL
       - Datos que el modelo NUNCA vio
       - Mide el rendimiento real
       - Solo se usa AL FINAL
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Args:
        X: Secuencias de entrada
        y: Valores a predecir
        train_split: Porcentaje para entrenamiento (default: 0.6 = 60%)
        val_split: Porcentaje para validaciÃ³n (default: 0.2 = 20%)
                   El resto (20%) serÃ¡ para test
    
    Returns:
        tuple: (X_train, X_val, X_test, y_train, y_val, y_test)
    """
    # Calcular Ã­ndices de divisiÃ³n
    train_size = int(len(X) * train_split)
    val_size = int(len(X) * val_split)
    
    # DivisiÃ³n cronolÃ³gica:
    # 1. TRAIN: desde inicio hasta train_size
    X_train = X[:train_size]
    y_train = y[:train_size]
    
    # 2. VALIDATION: desde train_size hasta train_size + val_size
    X_val = X[train_size:train_size + val_size]
    y_val = y[train_size:train_size + val_size]
    
    # 3. TEST: desde train_size + val_size hasta el final
    X_test = X[train_size + val_size:]
    y_test = y[train_size + val_size:]
    
    # Calcular porcentajes reales
    test_split = 1 - train_split - val_split
    
    # Mostrar informaciÃ³n
    print(f"âœ… Datos divididos en 3 conjuntos")
    print(f"   TRAIN      : {len(X_train)} muestras ({train_split*100:.0f}%)")
    print(f"   VALIDATION : {len(X_val)} muestras ({val_split*100:.0f}%)")
    print(f"   TEST       : {len(X_test)} muestras ({test_split*100:.0f}%)")
    print(f"   Total      : {len(X)} muestras")
    print(f"\n   ğŸ“… DivisiÃ³n temporal:")
    print(f"      Train: dÃ­as 1-{train_size}")
    print(f"      Val  : dÃ­as {train_size+1}-{train_size+val_size}")
    print(f"      Test : dÃ­as {train_size+val_size+1}-{len(X)}")
    
    return X_train, X_val, X_test, y_train, y_val, y_test


def reshape_for_lstm(X_train, X_val, X_test):
    """
    Reformatea datos para que LSTM los pueda procesar
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Â¿POR QUÃ‰ RESHAPE?
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    LSTM necesita datos en formato 3D:
    (nÃºmero_de_muestras, pasos_de_tiempo, caracterÃ­sticas)
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    EXPLICACIÃ“N DIMENSIONAL
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Antes del reshape:
    X_train.shape = (2154, 60)
    - 2154 muestras
    - 60 dÃ­as cada una
    
    DespuÃ©s del reshape:
    X_train.shape = (2154, 60, 1)
    - 2154 muestras
    - 60 pasos de tiempo (dÃ­as)
    - 1 caracterÃ­stica (solo temperatura)
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Â¿QUÃ‰ ES UNA CARACTERÃSTICA?
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Una caracterÃ­stica = una variable que medimos
    
    En nuestro caso: solo temperatura (1 caracterÃ­stica)
    
    Si tuviÃ©ramos mÃ¡s datos:
    [temperatura, humedad, viento] = 3 caracterÃ­sticas
    
    Args:
        X_train: Datos de entrenamiento (2D)
        X_val: Datos de validaciÃ³n (2D)
        X_test: Datos de prueba (2D)
    
    Returns:
        tuple: (X_train, X_val, X_test) en formato 3D
    """
    # reshape(samples, time_steps, features)
    # -1 en el primer parÃ¡metro = "calcula automÃ¡ticamente"
    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)
    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)
    
    print(f"âœ… Datos reformateados para LSTM")
    print(f"   X_train: {X_train.shape} â†’ (muestras, tiempo, caracterÃ­sticas)")
    print(f"   X_val  : {X_val.shape}")
    print(f"   X_test : {X_test.shape}")
    
    return X_train, X_val, X_test


def save_scaler(scaler):
    """
    Guarda el scaler en disco
    
    Â¿Por quÃ© guardar el scaler?
    Porque lo necesitaremos despuÃ©s para:
    1. Normalizar nuevos datos antes de predecir
    2. Desnormalizar las predicciones (convertir 0.5 â†’ 13Â°C)
    
    Args:
        scaler: Objeto MinMaxScaler entrenado
    """
    with open(SCALER_PATH, 'wb') as f:
        # pickle = librerÃ­a para guardar objetos de Python
        pickle.dump(scaler, f)
    print(f"âœ… Scaler guardado en {SCALER_PATH}")


def load_scaler():
    """
    Carga el scaler desde disco
    
    Returns:
        MinMaxScaler: Objeto scaler con min/max guardados
    """
    with open(SCALER_PATH, 'rb') as f:
        scaler = pickle.load(f)
    print(f"âœ… Scaler cargado desde {SCALER_PATH}")
    return scaler


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOQUE DE PRUEBA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸ§ª PROBANDO MÃ“DULO DE PREPROCESAMIENTO")
    print("="*70 + "\n")
    
    # Crear datos de ejemplo (10 temperaturas)
    test_data = np.array([[20], [21], [19], [22], [23], [24], [22], [21], [20], [19]])
    
    print("1ï¸âƒ£ NORMALIZACIÃ“N:")
    print("-"*70)
    scaled, scaler = normalize_data(test_data)
    print(f"   Primer valor: {test_data[0][0]}Â°C â†’ {scaled[0][0]:.4f}\n")
    
    print("2ï¸âƒ£ CREAR SECUENCIAS:")
    print("-"*70)
    X, y = create_sequences(scaled, time_steps=3)
    print(f"   Secuencia 0: {X[0]} â†’ predice {y[0]:.4f}\n")
    
    print("3ï¸âƒ£ DIVIDIR DATOS (Train/Val/Test):")
    print("-"*70)
    X_train, X_val, X_test, y_train, y_val, y_test = split_train_val_test(X, y, train_split=0.6, val_split=0.2)
    
    print("\n4ï¸âƒ£ RESHAPE PARA LSTM:")
    print("-"*70)
    X_train, X_val, X_test = reshape_for_lstm(X_train, X_val, X_test)
    
    print("\n" + "="*70)
    print("âœ… MÃ“DULO PROBADO CORRECTAMENTE")
    print("="*70)