"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MÃ“DULO: EVALUACIÃ“N DEL MODELO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PropÃ³sito: Calcular mÃ©tricas para medir el rendimiento del modelo

Funciones:
1. calculate_metrics() â†’ Calcula todas las mÃ©tricas
2. print_metrics() â†’ Muestra mÃ©tricas formateadas
3. evaluate_model() â†’ EvalÃºa el modelo completo
4. create_evaluation_report() â†’ Genera reporte en archivo
"""

import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pandas as pd


def calculate_metrics(y_true, y_pred):
    """
    Calcula todas las mÃ©tricas de evaluaciÃ³n
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    MÃ‰TRICAS CALCULADAS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    1. MSE (Mean Squared Error):
       - Promedio de errores al cuadrado
       - Penaliza mÃ¡s los errores grandes
       - Unidades: Â°CÂ²
       - FÃ³rmula: promedio((y_true - y_pred)Â²)
    
    2. RMSE (Root Mean Squared Error):
       - RaÃ­z cuadrada del MSE
       - MÃ¡s fÃ¡cil de interpretar (unidades: Â°C)
       - FÃ³rmula: âˆšMSE
       - Ejemplo: RMSE=2Â°C significa "me equivoco 2Â°C en promedio"
    
    3. MAE (Mean Absolute Error):
       - Promedio de errores absolutos
       - Todos los errores pesan igual
       - Unidades: Â°C
       - FÃ³rmula: promedio(|y_true - y_pred|)
       - Menos sensible a outliers que RMSE
    
    4. MAPE (Mean Absolute Percentage Error):
       - Error en porcentaje
       - FÃ¡cil de interpretar
       - Sin unidades (%)
       - FÃ³rmula: promedio(|y_true - y_pred| / |y_true|) Ã— 100
       - Ejemplo: MAPE=5% significa "5% de error promedio"
    
    5. RÂ² (R-squared / Coeficiente de DeterminaciÃ³n):
       - QuÃ© tan bien el modelo explica la variabilidad
       - Rango: -âˆ a 1 (1 es perfecto)
       - Sin unidades
       - RÂ²=0.85 significa "explica el 85% de la variaciÃ³n"
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Args:
        y_true: Valores reales (temperaturas reales)
        y_pred: Valores predichos (temperaturas predichas)
    
    Returns:
        dict: Diccionario con todas las mÃ©tricas
              {'MSE': ..., 'RMSE': ..., 'MAE': ..., 'MAPE': ..., 'R2': ...}
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PREPARACIÃ“N DE DATOS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Aplanar arrays si tienen mÃ¡s de 1 dimensiÃ³n
    # Ejemplo: [[20], [21], [19]] â†’ [20, 21, 19]
    y_true = y_true.flatten()
    y_pred = y_pred.flatten()
    
    """
    Â¿Por quÃ© flatten()?
    
    A veces los datos vienen en formato (n, 1):
    [[20],
     [21],
     [19]]
    
    Necesitamos formato (n,):
    [20, 21, 19]
    
    flatten() convierte cualquier dimensiÃ³n a 1D
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CALCULAR MÃ‰TRICAS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. MSE (Mean Squared Error)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    mse = mean_squared_error(y_true, y_pred)
    
    """
    Â¿QuÃ© hace mean_squared_error()?
    
    Paso a paso:
    1. Calcula errores: (y_true - y_pred)
    2. Eleva al cuadrado: (y_true - y_pred)Â²
    3. Promedia: suma(erroresÂ²) / n
    
    Ejemplo:
    y_true = [20, 21, 19]
    y_pred = [21, 22, 20]
    errores = [-1, -1, -1]
    erroresÂ² = [1, 1, 1]
    MSE = (1 + 1 + 1) / 3 = 1.0
    
    InterpretaciÃ³n:
    - MSE = 0 â†’ Perfecto
    - MSE = 1 â†’ Errores pequeÃ±os
    - MSE = 100 â†’ Errores grandes
    """
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. RMSE (Root Mean Squared Error)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    rmse = np.sqrt(mse)
    
    """
    Â¿Por quÃ© calcular RMSE?
    
    MSE tiene unidades raras (Â°CÂ²)
    RMSE tiene unidades normales (Â°C)
    
    Ejemplo:
    MSE = 4.0 (difÃ­cil de interpretar)
    RMSE = âˆš4.0 = 2.0Â°C (fÃ¡cil: "me equivoco 2 grados")
    
    RMSE es LA mÃ©trica mÃ¡s usada para regresiÃ³n
    porque es fÃ¡cil de entender.
    """
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. MAE (Mean Absolute Error)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    mae = mean_absolute_error(y_true, y_pred)
    
    """
    Â¿QuÃ© hace mean_absolute_error()?
    
    Paso a paso:
    1. Calcula errores: (y_true - y_pred)
    2. Toma valor absoluto: |errores|
    3. Promedia: suma(|errores|) / n
    
    Ejemplo:
    y_true = [20, 21, 28]
    y_pred = [21, 22, 20]
    errores = [-1, -1, 8]
    |errores| = [1, 1, 8]
    MAE = (1 + 1 + 8) / 3 = 3.33Â°C
    
    Diferencia con RMSE:
    MAE = 3.33 (todos los errores pesan igual)
    RMSE = 4.69 (penaliza mÃ¡s el error de 8)
    
    Â¿CuÃ¡l usar?
    - MAE: Si todos los errores son igual de malos
    - RMSE: Si los errores grandes son peores
    """
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. MAPE (Mean Absolute Percentage Error)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    # Calcular manualmente (scikit-learn no tiene MAPE built-in)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    
    """
    Â¿CÃ³mo se calcula MAPE?
    
    Paso a paso:
    1. Calcula errores: (y_true - y_pred)
    2. Toma valor absoluto: |errores|
    3. Divide por valor real: |errores| / y_true
    4. Promedia: promedio(...)
    5. Multiplica por 100 para obtener %
    
    Ejemplo:
    y_true = [20, 21]
    y_pred = [21, 22]
    
    errores = [-1, -1]
    |errores| = [1, 1]
    % errores = [1/20, 1/21] = [0.05, 0.0476]
    promedio = 0.0488
    MAPE = 0.0488 Ã— 100 = 4.88%
    
    InterpretaciÃ³n:
    MAPE = 4.88% â†’ "Me equivoco un 4.88% en promedio"
    
    Ventaja:
    - FÃ¡cil de entender
    - Permite comparar modelos en diferentes escalas
    
    LimitaciÃ³n:
    - No funciona bien si y_true tiene valores cercanos a 0
      (divisiÃ³n por casi cero)
    """
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. RÂ² (R-squared)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    r2 = r2_score(y_true, y_pred)
    
    """
    Â¿QuÃ© mide RÂ²?
    
    Compara tu modelo contra un modelo "tonto" que siempre
    predice el promedio.
    
    FÃ³rmula conceptual:
    RÂ² = 1 - (errores_tu_modelo / errores_modelo_promedio)
    
    Ejemplo:
    
    Datos reales: [10, 20, 30]
    Promedio: 20
    
    Modelo "tonto" (predice siempre 20):
    Predicciones: [20, 20, 20]
    Errores: [10, 0, 10]
    Suma erroresÂ²: 100 + 0 + 100 = 200
    
    Tu modelo LSTM:
    Predicciones: [11, 20, 29]
    Errores: [1, 0, 1]
    Suma erroresÂ²: 1 + 0 + 1 = 2
    
    RÂ² = 1 - (2 / 200) = 1 - 0.01 = 0.99 = 99%
    
    InterpretaciÃ³n:
    "Tu modelo explica el 99% de la variabilidad de los datos"
    "Es un 99% mejor que predecir siempre el promedio"
    
    Valores posibles:
    - RÂ² = 1.0 â†’ Perfecto (0% error)
    - RÂ² = 0.9 â†’ Excelente (explica 90%)
    - RÂ² = 0.5 â†’ Regular (explica 50%)
    - RÂ² = 0.0 â†’ Malo (igual que predecir promedio)
    - RÂ² < 0.0 â†’ Peor que predecir el promedio
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CREAR DICCIONARIO CON RESULTADOS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    metrics = {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'MAPE': mape,
        'R2': r2
    }
    
    return metrics


def print_metrics(metrics, dataset_name='Test'):
    """
    Imprime las mÃ©tricas de forma bonita y legible
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FORMATO DE SALIDA
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Muestra:
    1. Valores numÃ©ricos de cada mÃ©trica
    2. InterpretaciÃ³n cualitativa (Excelente/Bueno/Malo)
    3. Consejos sobre el rendimiento
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Args:
        metrics: Diccionario con las mÃ©tricas
        dataset_name: Nombre del conjunto ('Test', 'Train', 'Validation')
    """
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š MÃ‰TRICAS DE EVALUACIÃ“N - {dataset_name}")
    print(f"{'='*70}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SECCIÃ“N 1: MÃ©tricas de Error
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print(f"\nğŸ¯ Errores:")
    print(f"   MSE  (Mean Squared Error)        : {metrics['MSE']:.4f}")
    print(f"   RMSE (Root Mean Squared Error)   : {metrics['RMSE']:.4f} Â°C")
    print(f"   MAE  (Mean Absolute Error)       : {metrics['MAE']:.4f} Â°C")
    print(f"   MAPE (Mean Abs Percentage Error) : {metrics['MAPE']:.2f} %")
    
    """
    Formato de impresiÃ³n:
    
    {metrics['RMSE']:.4f}
         â†‘            â†‘
         â”‚            â””â”€ 4 decimales
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Valor de la mÃ©trica
    
    Ejemplo:
    Si RMSE = 2.123456
    Se imprime: 2.1235
    """
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SECCIÃ“N 2: Bondad de Ajuste
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print(f"\nğŸ“ˆ Bondad de ajuste:")
    print(f"   RÂ² (R-squared)                   : {metrics['R2']:.4f}")
    print(f"   Varianza explicada               : {metrics['R2']*100:.2f} %")
    
    """
    Â¿QuÃ© es "Varianza explicada"?
    
    Es RÂ² expresado en porcentaje.
    
    Ejemplo:
    RÂ² = 0.8542
    Varianza explicada = 85.42%
    
    Significa: "El modelo explica el 85.42% de las
                variaciones en la temperatura"
    """
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SECCIÃ“N 3: InterpretaciÃ³n Cualitativa
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print(f"\nğŸ’¡ InterpretaciÃ³n:")
    
    # Evaluar RÂ²
    if metrics['R2'] >= 0.9:
        print("   âœ… Excelente: El modelo explica muy bien los datos")
    elif metrics['R2'] >= 0.7:
        print("   ğŸ‘ Bueno: El modelo tiene buen desempeÃ±o")
    elif metrics['R2'] >= 0.5:
        print("   âš ï¸  Aceptable: El modelo puede mejorar")
    else:
        print("   âŒ Malo: El modelo necesita mejoras significativas")
    
    """
    Escala de calidad basada en RÂ²:
    
    RÂ² â‰¥ 0.9  â†’ Excelente (explica >90% de variaciÃ³n)
    RÂ² â‰¥ 0.7  â†’ Bueno (explica 70-90%)
    RÂ² â‰¥ 0.5  â†’ Aceptable (explica 50-70%)
    RÂ² < 0.5  â†’ Malo (explica <50%)
    
    Estas son guÃ­as generales.
    Para temperaturas, esperamos RÂ² â‰¥ 0.8
    """
    
    # Evaluar MAPE
    if metrics['MAPE'] <= 5:
        print("   âœ… Error porcentual muy bajo (<5%)")
    elif metrics['MAPE'] <= 10:
        print("   ğŸ‘ Error porcentual aceptable (5-10%)")
    else:
        print("   âš ï¸  Error porcentual alto (>10%)")
    
    """
    Escala de calidad basada en MAPE:
    
    MAPE â‰¤ 5%   â†’ Excelente
    MAPE â‰¤ 10%  â†’ Bueno
    MAPE â‰¤ 20%  â†’ Aceptable
    MAPE > 20%  â†’ Malo
    
    Para predicciÃ³n de temperatura:
    MAPE < 5% es un rendimiento excelente
    """
    
    # Evaluar RMSE (contexto: temperaturas en Melbourne 0-26Â°C)
    if metrics['RMSE'] <= 1.0:
        print("   âœ… RMSE excelente: errores <1Â°C")
    elif metrics['RMSE'] <= 2.0:
        print("   ğŸ‘ RMSE bueno: errores 1-2Â°C")
    elif metrics['RMSE'] <= 3.0:
        print("   âš ï¸  RMSE aceptable: errores 2-3Â°C")
    else:
        print("   âš ï¸  RMSE alto: errores >3Â°C - considerar mejorar el modelo")
    
    """
    Contexto de RMSE para temperaturas:
    
    Rango de datos: 0-26Â°C (26Â°C de variaciÃ³n)
    
    RMSE â‰¤ 1Â°C  â†’ Excelente (error <4% del rango)
    RMSE â‰¤ 2Â°C  â†’ Bueno (error <8% del rango)
    RMSE â‰¤ 3Â°C  â†’ Aceptable (error <12% del rango)
    RMSE > 3Â°C  â†’ Malo (error >12% del rango)
    
    Estos umbrales dependen del contexto:
    - PredicciÃ³n a corto plazo: RMSE < 1Â°C
    - PredicciÃ³n a largo plazo: RMSE < 3Â°C aceptable
    """
    
    print(f"{'='*70}\n")


def evaluate_model(model, X_test, y_test, scaler):
    """
    EvalÃºa el modelo completo en datos de prueba
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PROCESO DE EVALUACIÃ“N
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    1. Hacer predicciones con datos de test
    2. Desnormalizar predicciones y valores reales
    3. Calcular mÃ©tricas
    4. Mostrar resultados
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Args:
        model: Modelo LSTM entrenado
        X_test: Datos de entrada de prueba (normalizados)
        y_test: Valores reales de prueba (normalizados)
        scaler: Scaler para desnormalizar
    
    Returns:
        tuple: (predicciones, mÃ©tricas)
               - predicciones: Array con temperaturas predichas (Â°C)
               - mÃ©tricas: Diccionario con todas las mÃ©tricas
    """
    
    print("ğŸ” Evaluando modelo en datos de prueba...\n")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 1: Hacer Predicciones
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    predictions_scaled = model.predict(X_test, verbose=0)
    
    """
    Â¿QuÃ© hace model.predict()?
    
    Toma los datos de entrada (X_test) y genera predicciones
    
    X_test shape: (n_samples, 60, 1)
    predictions_scaled shape: (n_samples, 1)
    
    Ejemplo:
    X_test tiene 718 secuencias de 60 dÃ­as
    predictions_scaled tendrÃ¡ 718 predicciones
    
    verbose=0 â†’ No mostrar barra de progreso
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 2: Desnormalizar
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Desnormalizar predicciones (de 0-1 a Â°C)
    predictions = scaler.inverse_transform(predictions_scaled)
    
    # Desnormalizar valores reales (de 0-1 a Â°C)
    y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1))
    
    """
    Â¿Por quÃ© desnormalizar?
    
    Durante el entrenamiento trabajamos con valores 0-1
    Para evaluar necesitamos volver a escala original (Â°C)
    
    Ejemplo:
    PredicciÃ³n normalizada: 0.7
    Rango original: 0-26Â°C
    PredicciÃ³n desnormalizada: 0.7 Ã— 26 = 18.2Â°C
    
    scaler.inverse_transform() revierte la normalizaciÃ³n:
    valor_original = valor_normalizado Ã— (max - min) + min
    
    reshape(-1, 1) â†’ Convierte (n,) a (n, 1)
    Porque scaler espera formato (n, 1)
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 3: Calcular MÃ©tricas
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    metrics = calculate_metrics(y_test_original, predictions)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 4: Mostrar Resultados
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    print_metrics(metrics)
    
    return predictions, metrics


def create_evaluation_report(metrics, save_path='reports/metricas.txt'):
    """
    Crea un reporte de texto con las mÃ©tricas
    
    Â¿Para quÃ©?
    - Guardar resultados para comparar despuÃ©s
    - Documentar el rendimiento del modelo
    - Compartir resultados con otros
    
    Args:
        metrics: Diccionario con las mÃ©tricas
        save_path: Ruta donde guardar el reporte
    """
    
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write("="*60 + "\n")
        f.write("REPORTE DE EVALUACIÃ“N - PREDICCIÃ“N DE TEMPERATURA\n")
        f.write("="*60 + "\n\n")
        
        f.write("MÃ‰TRICAS DE ERROR:\n")
        f.write("-"*60 + "\n")
        f.write(f"MSE  (Mean Squared Error)        : {metrics['MSE']:.4f}\n")
        f.write(f"RMSE (Root Mean Squared Error)   : {metrics['RMSE']:.4f} Â°C\n")
        f.write(f"MAE  (Mean Absolute Error)       : {metrics['MAE']:.4f} Â°C\n")
        f.write(f"MAPE (Mean Abs Percentage Error) : {metrics['MAPE']:.2f} %\n\n")
        
        f.write("BONDAD DE AJUSTE:\n")
        f.write("-"*60 + "\n")
        f.write(f"RÂ² (R-squared)                   : {metrics['R2']:.4f}\n")
        f.write(f"Varianza explicada               : {metrics['R2']*100:.2f} %\n\n")
        
        f.write("INTERPRETACIÃ“N:\n")
        f.write("-"*60 + "\n")
        
        # InterpretaciÃ³n de RÂ²
        if metrics['R2'] >= 0.9:
            f.write("âœ… Excelente: El modelo explica muy bien los datos\n")
        elif metrics['R2'] >= 0.7:
            f.write("ğŸ‘ Bueno: El modelo tiene buen desempeÃ±o\n")
        elif metrics['R2'] >= 0.5:
            f.write("âš ï¸  Aceptable: El modelo puede mejorar\n")
        else:
            f.write("âŒ Malo: El modelo necesita mejoras significativas\n")
        
        # InterpretaciÃ³n de MAPE
        if metrics['MAPE'] <= 5:
            f.write("âœ… Error porcentual muy bajo (<5%)\n")
        elif metrics['MAPE'] <= 10:
            f.write("ğŸ‘ Error porcentual aceptable (5-10%)\n")
        else:
            f.write("âš ï¸  Error porcentual alto (>10%)\n")
        
        # InterpretaciÃ³n de RMSE
        if metrics['RMSE'] <= 1.0:
            f.write("âœ… RMSE excelente: errores <1Â°C\n")
        elif metrics['RMSE'] <= 2.0:
            f.write("ğŸ‘ RMSE bueno: errores 1-2Â°C\n")
        elif metrics['RMSE'] <= 3.0:
            f.write("âš ï¸  RMSE aceptable: errores 2-3Â°C\n")
        else:
            f.write("âš ï¸  RMSE alto: errores >3Â°C\n")
        
        f.write("\n" + "="*60 + "\n")
    
    print(f"âœ… Reporte guardado en {save_path}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOQUE DE PRUEBA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸ§ª PROBANDO MÃ“DULO DE EVALUACIÃ“N")
    print("="*70 + "\n")
    
    # Crear datos de ejemplo
    np.random.seed(42)  # Para reproducibilidad
    
    # Simular predicciones y valores reales
    y_true = np.array([20.5, 21.0, 19.5, 22.0, 23.5, 24.0, 22.5, 21.5, 20.0, 19.0])
    y_pred = np.array([20.8, 21.2, 19.3, 22.3, 23.2, 24.5, 22.7, 21.3, 20.2, 18.8])
    
    print("ğŸ“Š Datos de ejemplo:")
    print(f"   Valores reales     : {y_true[:5]}... (10 valores)")
    print(f"   Valores predichos  : {y_pred[:5]}... (10 valores)\n")
    
    # Calcular mÃ©tricas
    print("ğŸ“ˆ Calculando mÃ©tricas...\n")
    metrics = calculate_metrics(y_true, y_pred)
    
    # Mostrar mÃ©tricas
    print_metrics(metrics, dataset_name='Ejemplo')
    
    print("\nğŸ’¡ Nota: Para evaluar el modelo real, usa el script train.py")
    print("="*70)