# ğŸŒ¡ï¸ PredicciÃ³n de Temperatura con LSTM

Sistema completo de Machine Learning para predecir temperaturas mÃ­nimas diarias usando redes neuronales LSTM.

---

## ğŸ“‹ Tabla de Contenidos

1. [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
2. [Â¿QuÃ© es Machine Learning?](#-quÃ©-es-machine-learning)
3. [Â¿QuÃ© son las Redes LSTM?](#-quÃ©-son-las-redes-lstm)
4. [Estructura del Proyecto](#-estructura-del-proyecto)
5. [InstalaciÃ³n](#-instalaciÃ³n)
6. [Uso](#-uso)
7. [Resultados](#-resultados)
8. [CÃ³mo Funciona](#-cÃ³mo-funciona)
9. [MÃ©tricas de EvaluaciÃ³n](#-mÃ©tricas-de-evaluaciÃ³n)
10. [Mejoras Futuras](#-mejoras-futuras)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto predice **temperaturas mÃ­nimas diarias** en Melbourne, Australia, usando:

- **Datos**: 10 aÃ±os de temperaturas (1981-1990)
- **Modelo**: Red neuronal LSTM (Long Short-Term Memory)
- **Objetivo**: Predecir la temperatura de maÃ±ana basÃ¡ndose en los Ãºltimos 60 dÃ­as

### Â¿Por quÃ© es Ãºtil?

- ğŸŒ¾ **Agricultura**: Planificar cultivos y protecciÃ³n ante heladas
- ğŸ­ **EnergÃ­a**: Predecir demanda de calefacciÃ³n/refrigeraciÃ³n
- ğŸƒ **Eventos**: Planificar actividades al aire libre
- ğŸ“š **EducaciÃ³n**: Aprender Machine Learning con un caso real

---

## ğŸ¤– Â¿QuÃ© es Machine Learning?

**Machine Learning** (Aprendizaje AutomÃ¡tico) es enseÃ±ar a las computadoras a aprender de datos sin programarlas explÃ­citamente.

### AnalogÃ­a Simple

**ProgramaciÃ³n Tradicional**:

```
SI temperatura_ayer > 20Â°C ENTONCES
    temperatura_hoy = temperatura_ayer + ruido
```

**Machine Learning**:

```
Le damos 10 aÃ±os de temperaturas â†’
La computadora descubre los patrones â†’
Puede predecir temperaturas futuras
```

### Tipos de Aprendizaje

1. **Supervisado** (Este proyecto): Aprender de ejemplos con respuestas
2. **No supervisado**: Encontrar patrones sin respuestas
3. **Refuerzo**: Aprender mediante prueba y error

---

## ğŸ§  Â¿QuÃ© son las Redes LSTM?

**LSTM** = Long Short-Term Memory (Memoria de Largo y Corto Plazo)

### Â¿Por quÃ© LSTM para temperaturas?

Las temperaturas tienen **memoria**:

- La temperatura de hoy depende de ayer
- Y de la semana pasada
- Y de la estaciÃ³n del aÃ±o

**LSTM recuerda patrones temporales**:

```
DÃ­a 1: 15Â°C â”€â”
DÃ­a 2: 16Â°C  â”œâ”€â†’ LSTM aprende: "estÃ¡ subiendo"
DÃ­a 3: 17Â°C â”€â”˜
DÃ­a 4: Â¿?Â°C â†’ PredicciÃ³n: ~18Â°C
```

### Ventajas sobre otros modelos

| Modelo           | Memoria        | PredicciÃ³n           |
| ---------------- | -------------- | -------------------- |
| RegresiÃ³n Lineal | âŒ No          | Solo promedio        |
| RNN Simple       | âš ï¸ Corto plazo | Se olvida del pasado |
| **LSTM**         | âœ… Largo plazo | Recuerda patrones    |

---

## ğŸ“ Estructura del Proyecto

```
prediccion-temperatura/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ load_data.py                    # Carga y normaliza datos
â”‚   â””â”€â”€ daily-min-temperatures.csv      # Dataset (3650 dÃ­as)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py                # Crea secuencias y divide datos
â”‚   â”œâ”€â”€ model.py                        # Define arquitectura LSTM
â”‚   â”œâ”€â”€ evaluation.py                   # Calcula mÃ©tricas (RMSE, MAE, RÂ²)
â”‚   â””â”€â”€ visualization.py                # Crea grÃ¡ficas
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ lstm_temperatura.keras          # Modelo entrenado (guardado)
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ temperatura_historica.png       # Datos originales
â”‚   â”œâ”€â”€ entrenamiento.png               # Progreso del entrenamiento
â”‚   â”œâ”€â”€ predicciones.png                # Predicciones vs Realidad
â”‚   â”œâ”€â”€ scatter.png                     # GrÃ¡fica de dispersiÃ³n
â”‚   â”œâ”€â”€ errores.png                     # AnÃ¡lisis de errores
â”‚   â””â”€â”€ metricas.txt                    # Reporte de mÃ©tricas
â”‚
â”œâ”€â”€ web/
â”‚   â””â”€â”€ __init__.py                     # (Futuro: interfaz web)
â”‚
â”œâ”€â”€ config.py                           # ConfiguraciÃ³n global
â”œâ”€â”€ train.py                            # Script principal ğŸš€
â”œâ”€â”€ requirements.txt                    # Dependencias
â””â”€â”€ README.md                           # Este archivo
```

---

## ğŸ”§ InstalaciÃ³n

### Requisitos Previos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Paso 1: Clonar/Descargar el Proyecto

```bash
# Si tienes el proyecto en GitHub
git clone https://github.com/tu-usuario/prediccion-temperatura.git
cd prediccion-temperatura

# O simplemente descarga la carpeta completa
```

### Paso 2: Crear Entorno Virtual (Recomendado)

```bash
# En Windows
python -m venv venv
venv\Scripts\activate

# En Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### Paso 3: Instalar Dependencias

```bash
pip install -r requirements.txt
```

Esto instalarÃ¡:

- `numpy`: Operaciones matemÃ¡ticas
- `pandas`: Manejo de datos
- `tensorflow`: Framework de Deep Learning
- `scikit-learn`: Preprocesamiento y mÃ©tricas
- `matplotlib`: Visualizaciones

### Paso 4: Verificar InstalaciÃ³n

```bash
python -c "import tensorflow; print('TensorFlow:', tensorflow.__version__)"
```

---

## ğŸš€ Uso

### Entrenamiento Completo

Ejecutar el pipeline completo (5-10 minutos):

```bash
python train.py
```

Esto ejecutarÃ¡:

1. âœ… Carga de datos
2. âœ… Preprocesamiento
3. âœ… Entrenamiento del modelo (50 Ã©pocas)
4. âœ… EvaluaciÃ³n
5. âœ… GeneraciÃ³n de grÃ¡ficas
6. âœ… Guardado del modelo

### Uso ProgramÃ¡tico

```python
# Entrenar modelo
from train import train_model
model, history, metrics = train_model()

# Hacer predicciones con modelo guardado
from tensorflow import keras
import numpy as np

# Cargar modelo
model = keras.models.load_model('models/lstm_temperatura.keras')

# Predecir (necesitas 60 dÃ­as normalizados)
secuencia = np.array([...])  # 60 temperaturas normalizadas
prediccion = model.predict(secuencia)
```

### Modificar HiperparÃ¡metros

Edita `config.py` o `train.py`:

```python
# Cambiar cantidad de Ã©pocas
epochs = 100  # Default: 50

# Cambiar tamaÃ±o de secuencia
sequence_length = 90  # Default: 60

# Cambiar arquitectura
lstm_units_1 = 100  # Default: 50
```

---

## ğŸ“Š Resultados

### MÃ©tricas Esperadas

Con los parÃ¡metros por defecto:

| MÃ©trica  | Valor Esperado | InterpretaciÃ³n          |
| -------- | -------------- | ----------------------- |
| **RMSE** | 1.5 - 2.5Â°C    | Error promedio en Â°C    |
| **MAE**  | 1.2 - 2.0Â°C    | Error absoluto promedio |
| **MAPE** | 5 - 10%        | Error porcentual        |
| **RÂ²**   | 0.75 - 0.90    | % de varianza explicada |

### Ejemplo Real

```
RMSE: 1.87Â°C
MAE:  1.45Â°C
MAPE: 7.23%
RÂ²:   0.8542 (85.42% varianza explicada)

InterpretaciÃ³n:
âœ… Excelente: El modelo predice con ~2Â°C de error
âœ… Error porcentual aceptable (< 10%)
âœ… Explica el 85% de las variaciones
```

### GrÃ¡ficas Generadas

1. **Temperatura HistÃ³rica**: Visualiza 10 aÃ±os de datos
2. **Progreso de Entrenamiento**: PÃ©rdida vs Ã©pocas
3. **Predicciones vs Realidad**: ComparaciÃ³n visual
4. **DispersiÃ³n**: Cada punto = (real, predicciÃ³n)
5. **AnÃ¡lisis de Errores**: DistribuciÃ³n de errores

---

## ğŸ” CÃ³mo Funciona

### Pipeline Completo

```
DATOS
â†“
1. Carga â†’ CSV con 3650 temperaturas
â†“
2. NormalizaciÃ³n â†’ Escalar a rango [0, 1]
â†“
3. Secuencias â†’ Crear ventanas de 60 dÃ­as
   [dÃ­a1...dÃ­a60] â†’ dÃ­a61
   [dÃ­a2...dÃ­a61] â†’ dÃ­a62
   ...
â†“
4. DivisiÃ³n â†’ Train (70%) / Val (15%) / Test (15%)
â†“
5. Modelo LSTM â†’ Arquitectura:
   - Input: 60 dÃ­as
   - LSTM 1: 50 neuronas
   - Dropout: 20%
   - LSTM 2: 50 neuronas
   - Dropout: 20%
   - Dense: 1 neurona (predicciÃ³n)
â†“
6. Entrenamiento â†’ 50 Ã©pocas, batch_size=32
â†“
7. EvaluaciÃ³n â†’ Calcular RMSE, MAE, MAPE, RÂ²
â†“
8. VisualizaciÃ³n â†’ Generar 5 grÃ¡ficas
â†“
9. Guardado â†’ Modelo .keras + reportes
```

### Ejemplo de PredicciÃ³n

```python
# Datos de entrada (Ãºltimos 60 dÃ­as)
Input: [15.2, 15.8, 16.1, ..., 18.3, 18.9, 19.2]
        â†“
     [LSTM Layer 1]
        â†“
     [LSTM Layer 2]
        â†“
      [Dense]
        â†“
Output: 19.7Â°C  (predicciÃ³n para dÃ­a 61)
```

---

## ğŸ“ MÃ©tricas de EvaluaciÃ³n

### 1. RMSE (Root Mean Squared Error)

**FÃ³rmula**: âˆš(promedio((real - predicciÃ³n)Â²))

**InterpretaciÃ³n**:

- RMSE = 2.0Â°C â†’ "Me equivoco 2Â°C en promedio"
- Penaliza mÃ¡s los errores grandes

**Escala de calidad**:

- âœ… Excelente: < 1Â°C
- ğŸ‘ Bueno: 1-2Â°C
- âš ï¸ Aceptable: 2-3Â°C
- âŒ Malo: > 3Â°C

### 2. MAE (Mean Absolute Error)

**FÃ³rmula**: promedio(|real - predicciÃ³n|)

**InterpretaciÃ³n**:

- MAE = 1.5Â°C â†’ "Error absoluto promedio de 1.5Â°C"
- Todos los errores pesan igual

### 3. MAPE (Mean Absolute Percentage Error)

**FÃ³rmula**: promedio(|real - predicciÃ³n| / real) Ã— 100

**InterpretaciÃ³n**:

- MAPE = 7% â†’ "Me equivoco un 7% en promedio"
- FÃ¡cil de entender

**Escala de calidad**:

- âœ… Excelente: < 5%
- ğŸ‘ Bueno: 5-10%
- âš ï¸ Aceptable: 10-20%
- âŒ Malo: > 20%

### 4. RÂ² (R-squared)

**FÃ³rmula**: 1 - (errores_modelo / errores_modelo_promedio)

**InterpretaciÃ³n**:

- RÂ² = 0.85 â†’ "Explica el 85% de la variabilidad"
- Compara tu modelo vs predecir siempre el promedio

**Escala de calidad**:

- âœ… Excelente: > 0.90
- ğŸ‘ Bueno: 0.70-0.90
- âš ï¸ Aceptable: 0.50-0.70
- âŒ Malo: < 0.50

---

## ğŸš€ Mejoras Futuras

### TÃ©cnicas Avanzadas

1. **Arquitectura**:

   - âœ… Bidirectional LSTM
   - âœ… Attention Mechanism
   - âœ… GRU (alternativa a LSTM)

2. **Datos**:

   - âœ… Agregar mÃ¡s features (humedad, presiÃ³n, viento)
   - âœ… Usar datos de mÃºltiples ciudades
   - âœ… Incorporar datos meteorolÃ³gicos

3. **Entrenamiento**:
   - âœ… Learning rate scheduling
   - âœ… Early stopping mÃ¡s sofisticado
   - âœ… Cross-validation temporal

### Funcionalidades

1. **Interfaz Web** (Streamlit/Flask):

   ```
   - Subir datos personalizados
   - Visualizar predicciones en tiempo real
   - Comparar mÃºltiples modelos
   ```

2. **API REST**:

   ```python
   POST /predict
   Body: {"last_60_days": [15, 16, ...]}
   Response: {"prediction": 19.7, "confidence": 0.85}
   ```

3. **Dashboard Interactivo**:
   - GrÃ¡ficas interactivas con Plotly
   - SelecciÃ³n de rango de fechas
   - Exportar reportes en PDF

---

## ğŸ“š Recursos de Aprendizaje

### Machine Learning BÃ¡sico

- [Coursera: Machine Learning (Andrew Ng)](https://www.coursera.org/learn/machine-learning)
- [StatQuest: Machine Learning](https://www.youtube.com/c/joshstarmer)

### Deep Learning y LSTM

- [Deep Learning Book (Goodfellow)](https://www.deeplearningbook.org/)
- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)

### TensorFlow/Keras

- [TensorFlow Documentation](https://www.tensorflow.org/tutorials)
- [Keras API Reference](https://keras.io/api/)

### Series Temporales

- [Forecasting: Principles and Practice](https://otexts.com/fpp3/)

---

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas!

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/mejora`)
3. Commit tus cambios (`git commit -m 'AÃ±adir mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.

---

## ğŸ‘¤ Autor

Proyecto educativo creado para enseÃ±ar Machine Learning desde cero.

---

## â“ Preguntas Frecuentes

### Â¿Por quÃ© 60 dÃ­as como secuencia?

60 dÃ­as (~2 meses) captura:

- Patrones semanales
- Tendencias mensuales
- Sin ser demasiado largo (overfitting)

Puedes probar con 30, 90 o 120 dÃ­as.

### Â¿Por quÃ© LSTM y no otro modelo?

| Modelo         | Pros                            | Contras                       |
| -------------- | ------------------------------- | ----------------------------- |
| Promedio MÃ³vil | Simple                          | No captura patrones complejos |
| ARIMA          | Bueno para series estacionarias | Asume linealidad              |
| **LSTM**       | Captura patrones no lineales    | MÃ¡s complejo                  |
| Transformer    | Estado del arte                 | Necesita muchos datos         |

LSTM es el equilibrio perfecto para este problema.

### Â¿CÃ³mo mejoro el modelo?

1. **MÃ¡s Ã©pocas**: epochs=100
2. **MÃ¡s datos**: Agregar mÃ¡s aÃ±os
3. **MÃ¡s features**: Humedad, presiÃ³n, etc.
4. **Mejor arquitectura**: MÃ¡s capas LSTM
5. **Hyperparameter tuning**: Grid search

### Â¿Puedo usar otros datos?

Â¡SÃ­! Solo necesitas:

1. Un CSV con fechas y valores numÃ©ricos
2. Al menos 1000 observaciones
3. Modificar `load_data.py` para tu formato

---

## ğŸ‰ Â¡Felicidades!

Si llegaste hasta aquÃ­, ya sabes cÃ³mo funciona un sistema completo de Machine Learning.

**Has aprendido**:

- âœ… Carga y preprocesamiento de datos
- âœ… Redes neuronales LSTM
- âœ… Entrenamiento y evaluaciÃ³n
- âœ… VisualizaciÃ³n de resultados
- âœ… Despliegue de modelos

**PrÃ³ximos pasos**:

1. Ejecuta `python train.py`
2. Analiza las grÃ¡ficas
3. Experimenta con parÃ¡metros
4. Â¡Crea tu propio proyecto!

---

**Â¿Preguntas o problemas?**

- Abre un Issue en GitHub
- Consulta la documentaciÃ³n de TensorFlow
- Busca en Stack Overflow

Â¡Buena suerte con tu aprendizaje! ğŸš€ğŸ“ŠğŸ§ 
