# ğŸ§  Deep Learning Repository - Proyectos de Machine Learning

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.7.2-orange.svg)](https://scikit-learn.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![GitHub repo](https://img.shields.io/badge/GitHub-repos--deep--learning-181717?logo=github)](https://github.com/devlitus/repos-deep-learning)

Repositorio educativo con **tres proyectos independientes de Machine Learning** siguiendo arquitectura modular y mejores prÃ¡cticas:

- ğŸ  **Predictor de Precios de Casas**: RegresiÃ³n lineal mÃºltiple para estimar precios inmobiliarios
- ğŸš¢ **Predictor de Supervivencia del Titanic**: ClasificaciÃ³n binaria con Random Forest
- ğŸ’³ **DetecciÃ³n de Fraude**: Sistema avanzado de detecciÃ³n de transacciones fraudulentas con tÃ©cnicas de balanceo

Cada proyecto incluye pipeline completo: carga de datos â†’ preprocesamiento â†’ entrenamiento â†’ evaluaciÃ³n â†’ predicciones.

## ğŸ¯ Proyectos Incluidos

### ğŸ  Predictor de Precios de Casas (`predictor-house/`)

**Tipo**: RegresiÃ³n Lineal MÃºltiple  
**Dataset**: Kaggle House Prices + Dataset sintÃ©tico local  
**Objetivo**: Predecir precios de viviendas basÃ¡ndose en caracterÃ­sticas fÃ­sicas y ubicaciÃ³n

**CaracterÃ­sticas clave**:

- ğŸ“Š AnÃ¡lisis de 5 variables: tamaÃ±o, habitaciones, baÃ±os, edad, distancia al centro
- ğŸ“ˆ RegresiÃ³n lineal con scikit-learn
- ğŸ¨ Visualizaciones de correlaciones y predicciones
- ğŸ”® Sistema de predicciÃ³n para nuevas propiedades
- ğŸ“¦ Tres implementaciones: modelo simple, Kaggle lineal, Kaggle Random Forest

**MÃ©tricas de evaluaciÃ³n**: RÂ² Score, MAE, RMSE

### ğŸš¢ Predictor de Supervivencia del Titanic (`predictor-titanic/`)

**Tipo**: ClasificaciÃ³n Binaria  
**Dataset**: Titanic dataset (Seaborn)  
**Objetivo**: Predecir supervivencia de pasajeros del Titanic

**CaracterÃ­sticas clave**:

- ğŸ« AnÃ¡lisis de 7 features: clase, sexo, edad, tarifa, embarque, familia
- ğŸŒ² Random Forest Classifier
- ğŸ§¹ Pipeline robusto de preprocesamiento (manejo de nulos, encoding)
- ğŸ“Š Visualizaciones exploratorias detalladas
- ğŸ¯ Feature engineering (family_size, is_alone)

**MÃ©tricas de evaluaciÃ³n**: Accuracy, Precision, Recall, F1-Score, Matriz de confusiÃ³n

### ğŸ’³ DetecciÃ³n de Fraude en Tarjetas de CrÃ©dito (`fraude-detection/`)

**Tipo**: ClasificaciÃ³n Binaria con Datos Desbalanceados  
**Dataset**: Credit Card Fraud Detection (Kaggle)  
**Objetivo**: Identificar transacciones fraudulentas en tiempo real

**CaracterÃ­sticas clave**:

- ğŸ¯ **Datos altamente desbalanceados**: <0.2% de fraudes en el dataset
- âš–ï¸ **TÃ©cnicas de balanceo**: SMOTE (Synthetic Minority Oversampling Technique)
- ğŸŒ² Random Forest optimizado para detecciÃ³n de anomalÃ­as
- ğŸ“Š AnÃ¡lisis exploratorio completo con 4 notebooks interactivos
- ğŸŒ **AplicaciÃ³n web Streamlit** con mÃºltiples pÃ¡ginas:
  - Dashboard principal con mÃ©tricas clave
  - PredicciÃ³n de transacciones individuales
  - AnÃ¡lisis de datos exploratorio
  - Analytics avanzado con visualizaciones
- ğŸ”„ Pipeline completo: EDA â†’ Preprocesamiento â†’ Balanceo â†’ Entrenamiento â†’ EvaluaciÃ³n
- ğŸ’¾ Persistencia de datos procesados y splits para reproducibilidad

**MÃ©tricas de evaluaciÃ³n**: Accuracy (~99.9%), Precision (95%), Recall (85%), F1-Score (90%), AUC-ROC (0.95)

## ğŸ“ Estructura del Repositorio

```
repos-deep-learning/
â”‚
â”œâ”€â”€ predictor-house/           # ğŸ  Proyecto de RegresiÃ³n (Precios Casas)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/              # Datos originales (casas.csv + Kaggle datasets)
â”‚   â”‚   â””â”€â”€ processed/        # Datos procesados
â”‚   â”œâ”€â”€ src/                  # MÃ³dulos Python
â”‚   â”‚   â”œâ”€â”€ data_loader.py    # Carga y exploraciÃ³n
â”‚   â”‚   â”œâ”€â”€ model.py          # Entrenamiento/evaluaciÃ³n
â”‚   â”‚   â”œâ”€â”€ predictor.py      # Predicciones
â”‚   â”‚   â”œâ”€â”€ visualizations.py # GrÃ¡ficos
â”‚   â”‚   â””â”€â”€ explore_kaggle.py # AnÃ¡lisis Kaggle dataset
â”‚   â”œâ”€â”€ models/               # Modelos entrenados (.pkl)
â”‚   â”‚   â”œâ”€â”€ modelo_casas.pkl
â”‚   â”‚   â”œâ”€â”€ modelo_kaggle.pkl
â”‚   â”‚   â””â”€â”€ modelo_kaggle_rf.pkl
â”‚   â”œâ”€â”€ reports/figures/      # Visualizaciones generadas
â”‚   â”œâ”€â”€ main.py               # Pipeline principal
â”‚   â”œâ”€â”€ main_kaggle.py        # Pipeline Kaggle (regresiÃ³n lineal)
â”‚   â”œâ”€â”€ main_kaggle_rf.py     # Pipeline Kaggle (Random Forest)
â”‚   â”œâ”€â”€ app.py                # AplicaciÃ³n Streamlit
â”‚   â”œâ”€â”€ config.py             # Configuraciones del proyecto
â”‚   â””â”€â”€ requirements.txt      # Dependencias especÃ­ficas
â”‚
â”œâ”€â”€ predictor-titanic/         # ğŸš¢ Proyecto de ClasificaciÃ³n (Titanic)
â”‚   â”œâ”€â”€ data/                 # (Dataset cargado desde seaborn)
â”‚   â”œâ”€â”€ src/                  # MÃ³dulos Python
â”‚   â”‚   â”œâ”€â”€ data_loader.py    # Carga dataset Titanic
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py  # Limpieza y feature engineering
â”‚   â”‚   â”œâ”€â”€ model.py          # Entrenamiento Random Forest
â”‚   â”‚   â”œâ”€â”€ visualization.py  # AnÃ¡lisis exploratorio
â”‚   â”‚   â””â”€â”€ predictor.py      # Predicciones
â”‚   â”œâ”€â”€ models/               # Modelos entrenados
â”‚   â”‚   â””â”€â”€ titanic_random_forest.pkl
â”‚   â”œâ”€â”€ reports/              # Reportes y visualizaciones
â”‚   â”œâ”€â”€ config.py             # Configuraciones del proyecto
â”‚   â”œâ”€â”€ main.py               # Pipeline completo
â”‚   â””â”€â”€ requirements.txt      # Dependencias especÃ­ficas
â”‚
â”œâ”€â”€ fraude-detection/          # ğŸ’³ Proyecto de DetecciÃ³n de Fraude
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/              # creditcard.csv (Kaggle)
â”‚   â”‚   â””â”€â”€ processed/        # Datos procesados y splits
â”‚   â”‚       â”œâ”€â”€ X_train_original.csv
â”‚   â”‚       â”œâ”€â”€ X_train_balanced.csv
â”‚   â”‚       â”œâ”€â”€ X_val.csv
â”‚   â”‚       â”œâ”€â”€ X_test.csv
â”‚   â”‚       â””â”€â”€ y_*.csv
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”œâ”€â”€ load.py       # Carga de datos
â”‚   â”‚   â”‚   â””â”€â”€ preprocess.py # Preprocesamiento y balanceo
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py      # Entrenamiento de modelos
â”‚   â”‚   â”‚   â””â”€â”€ evaluate.py   # EvaluaciÃ³n y mÃ©tricas
â”‚   â”‚   â””â”€â”€ visualization/
â”‚   â”‚       â””â”€â”€ plots.py      # GrÃ¡ficos y visualizaciones
â”‚   â”œâ”€â”€ web/                  # AplicaciÃ³n Streamlit multipÃ¡gina
â”‚   â”‚   â”œâ”€â”€ app.py            # App principal
â”‚   â”‚   â”œâ”€â”€ pages/            # PÃ¡ginas individuales
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prediction.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_explorer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics.py
â”‚   â”‚   â”‚   â””â”€â”€ about.py
â”‚   â”‚   â”œâ”€â”€ styles/           # CSS personalizado
â”‚   â”‚   â””â”€â”€ utils/            # Utilidades web
â”‚   â”œâ”€â”€ notebooks/            # 4 notebooks Jupyter
â”‚   â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â”‚   â””â”€â”€ 04_model_evaluation.ipynb
â”‚   â”œâ”€â”€ models/               # Modelos y reportes
â”‚   â”‚   â”œâ”€â”€ final_evaluation_report.csv
â”‚   â”‚   â”œâ”€â”€ final_evaluation_report.json
â”‚   â”‚   â””â”€â”€ model_metrics.csv
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.py         # Configuraciones centralizadas
â”‚   â”œâ”€â”€ main.py               # Pipeline completo
â”‚   â”œâ”€â”€ verify_installation.py # VerificaciÃ³n de setup
â”‚   â””â”€â”€ requirements.txt      # Dependencias especÃ­ficas
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md  # Instrucciones para agentes IA
â”œâ”€â”€ LICENSE                   # Licencia MIT
â””â”€â”€ README.md                 # Este archivo
```

### ğŸ—‚ï¸ PatrÃ³n de Arquitectura ComÃºn

Los proyectos siguen una estructura modular consistente:

- **`config.py`**: Rutas absolutas, features, hiperparÃ¡metros
- **`src/data_loader.py`**: Carga de datos desde fuentes locales/remotas
- **`src/model.py` o `train_model.py`**: Entrenamiento y evaluaciÃ³n
- **`src/visualizations.py`**: GeneraciÃ³n de grÃ¡ficos analÃ­ticos
- **`main.py`**: Pipeline completo ejecutable
- **`models/`**: Persistencia de modelos con pickle

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- Git (para clonar el repositorio)

### InstalaciÃ³n General

1. **Clonar el repositorio**

   ```powershell
   git clone https://github.com/devlitus/repos-deep-learning.git
   cd repos-deep-learning
   ```

2. **Crear entorno virtual (recomendado)**

   ```powershell
   python -m venv venv
   # Activar en Windows PowerShell
   .\venv\Scripts\Activate.ps1
   ```

### ğŸ  Ejecutar Predictor de Casas

```powershell
cd predictor-house
pip install -r requirements.txt
python main.py              # Pipeline con dataset simple
python main_kaggle.py       # Pipeline Kaggle (regresiÃ³n lineal)
python main_kaggle_rf.py    # Pipeline Kaggle (Random Forest)
streamlit run app.py        # AplicaciÃ³n web interactiva
```

**Output esperado**:

- Modelo entrenado en `models/modelo_casas.pkl`
- Visualizaciones en `reports/figures/`
- MÃ©tricas de evaluaciÃ³n en consola

### ğŸš¢ Ejecutar Predictor de Titanic

```powershell
cd predictor-titanic
pip install -r requirements.txt
python main.py              # Pipeline completo
```

**Output esperado**:

- Modelo Random Forest en `models/titanic_random_forest.pkl`
- AnÃ¡lisis detallado con prints formateados
- Matriz de confusiÃ³n y mÃ©tricas de clasificaciÃ³n

### ğŸ’³ Ejecutar DetecciÃ³n de Fraude

```powershell
cd fraude-detection
pip install -r requirements.txt

# Verificar instalaciÃ³n
python verify_installation.py

# Ejecutar pipeline completo
python main.py

# Lanzar aplicaciÃ³n web
streamlit run web/app.py

# Explorar notebooks
jupyter notebook notebooks/
```

**Output esperado**:

- Datos procesados en `data/processed/` (splits originales y balanceados)
- Modelos entrenados y mÃ©tricas en `models/`
- Reportes JSON en `reports/eda_insights.json`
- AplicaciÃ³n web interactiva en `http://localhost:8501`

## ğŸ“Š Ejemplos de Uso

### ğŸ  Predicciones de Precios de Casas

```python
import pickle
from src.predictor import predict_new_houses

# Cargar modelo entrenado
with open('predictor-house/models/modelo_casas.pkl', 'rb') as f:
    modelo = pickle.load(f)

# Formato: [tamaÃ±o_m2, habitaciones, baÃ±os, edad_aÃ±os, distancia_centro_km]
casas_nuevas = [
    [130, 3, 2, 10, 5.0],  # Casa mediana
    [200, 5, 4, 1, 2.0],   # Casa grande y nueva
]

predict_new_houses(modelo, casas_nuevas)
```

### ğŸš¢ AnÃ¡lisis de Supervivencia del Titanic

```python
import joblib
import pandas as pd

# Cargar modelo
modelo = joblib.load('predictor-titanic/models/titanic_random_forest.pkl')

# Ejemplo de pasajero
pasajero = pd.DataFrame({
    'pclass': [1],           # Primera clase
    'sex': [0],              # Mujer (codificado)
    'age': [28],             # 28 aÃ±os
    'fare': [80],            # Tarifa pagada
    'embarked': [0],         # Cherbourg
    'family_size': [2],      # Viaja con 1 familiar
    'is_alone': [0]          # No viaja solo
})

prediccion = modelo.predict(pasajero)
probabilidad = modelo.predict_proba(pasajero)
print(f"Supervivencia: {'âœ… SobreviviÃ³' if prediccion[0] else 'âŒ No sobreviviÃ³'}")
print(f"Probabilidad: {probabilidad[0][1]:.2%}")
```

### ğŸ’³ DetecciÃ³n de Transacciones Fraudulentas

```python
import joblib
import pandas as pd
import numpy as np

# Cargar modelo entrenado
modelo = joblib.load('fraude-detection/models/fraud_detection_model.pkl')

# Ejemplo de transacciÃ³n (features V1-V28 + Amount)
# En producciÃ³n, estas features vienen de PCA del dataset original
transaccion = pd.DataFrame({
    'V1': [-1.359807],
    'V2': [-0.072781],
    # ... V3 a V27 ...
    'V28': [0.014724],
    'Amount': [149.62],
    'Time': [0]
})

# Predecir
prediccion = modelo.predict(transaccion)
probabilidad = modelo.predict_proba(transaccion)

if prediccion[0] == 1:
    print(f"âš ï¸ FRAUDE DETECTADO - Confianza: {probabilidad[0][1]:.2%}")
else:
    print(f"âœ… TransacciÃ³n legÃ­tima - Confianza: {probabilidad[0][0]:.2%}")
```

## ğŸ“‹ Datasets Utilizados

### Predictor de Casas

| Variable              | DescripciÃ³n                | Tipo     | Rango       |
| --------------------- | -------------------------- | -------- | ----------- |
| `tamano_m2`           | Superficie en mÂ²           | NumÃ©rico | 70-200 mÂ²   |
| `habitaciones`        | NÃºmero de habitaciones     | Entero   | 1-5         |
| `banos`               | NÃºmero de baÃ±os            | Entero   | 1-4         |
| `edad_anos`           | AntigÃ¼edad de la propiedad | Entero   | 1-30 aÃ±os   |
| `distancia_centro_km` | Distancia al centro        | Decimal  | 1.8-18.0 km |
| `precio` ğŸ¯           | Precio (target)            | NumÃ©rico | $145K-$620K |

**Fuentes**:

- Dataset sintÃ©tico local (`casas.csv`)
- Kaggle House Prices Competition (`train.csv`, `test.csv`)

### Predictor de Titanic

| Variable      | DescripciÃ³n                 | Tipo       | Valores        |
| ------------- | --------------------------- | ---------- | -------------- |
| `pclass`      | Clase del ticket            | CategÃ³rico | 1, 2, 3        |
| `sex`         | Sexo del pasajero           | CategÃ³rico | male, female   |
| `age`         | Edad del pasajero           | NumÃ©rico   | 0.42-80 aÃ±os   |
| `fare`        | Tarifa pagada               | NumÃ©rico   | $0-$512        |
| `embarked`    | Puerto de embarque          | CategÃ³rico | C, Q, S        |
| `family_size` | TamaÃ±o familia (engineered) | Entero     | 1-11           |
| `is_alone`    | Viaja solo (engineered)     | Binario    | 0, 1           |
| `survived` ğŸ¯ | Supervivencia (target)      | Binario    | 0 (No), 1 (SÃ­) |

**Fuente**: Seaborn dataset (`sns.load_dataset('titanic')`)

### DetecciÃ³n de Fraude

| Variable     | DescripciÃ³n                        | Tipo     | Valores        |
| ------------ | ---------------------------------- | -------- | -------------- |
| `Time`       | Segundos desde primera transacciÃ³n | NumÃ©rico | 0-172,792      |
| `V1` - `V28` | Features de PCA (anÃ³nimas)         | NumÃ©rico | Normalizados   |
| `Amount`     | Monto de la transacciÃ³n            | NumÃ©rico | $0-$25,691     |
| `Class` ğŸ¯   | Fraude (target)                    | Binario  | 0 (No), 1 (SÃ­) |

**CaracterÃ­sticas del dataset**:

- **Total transacciones**: 284,807
- **Transacciones fraudulentas**: 492 (0.172%)
- **Desbalance**: 99.83% legÃ­timas vs 0.17% fraudes
- **Features**: 30 (28 de PCA + Time + Amount)
- **Fuente**: Kaggle Credit Card Fraud Detection

**TÃ©cnicas de balanceo aplicadas**:

- SMOTE (Synthetic Minority Oversampling Technique)
- Ratio de balanceo: 0.5 (50% minoritaria vs mayoritaria)

## ğŸ”¬ Rendimiento de los Modelos

### ğŸ  Predictor de Casas

#### Modelo Simple (RegresiÃ³n Lineal)

- **RÂ² Score**: Coeficiente de determinaciÃ³n
- **MAE**: Error absoluto medio en dÃ³lares
- **RMSE**: RaÃ­z del error cuadrÃ¡tico medio
- **Visualizaciones**: Predicciones vs valores reales

#### Modelo Kaggle Random Forest

- **Mejora significativa** sobre regresiÃ³n lineal simple
- **Tres implementaciones** para comparaciÃ³n de rendimiento
- **ExportaciÃ³n de predicciones** para submission en Kaggle

### ğŸš¢ Predictor de Titanic

#### Random Forest Classifier

- **Accuracy**: PrecisiÃ³n general del modelo
- **Precision/Recall**: Por clase (sobreviviÃ³/no sobreviviÃ³)
- **F1-Score**: Media armÃ³nica de precision y recall
- **Matriz de ConfusiÃ³n**: VisualizaciÃ³n de predicciones correctas/incorrectas
- **Feature Importance**: Variables mÃ¡s relevantes para la predicciÃ³n

### ğŸ’³ DetecciÃ³n de Fraude

#### Random Forest Optimizado con SMOTE

| MÃ©trica       | Valor | DescripciÃ³n                                     |
| ------------- | ----- | ----------------------------------------------- |
| **Accuracy**  | 99.9% | PrecisiÃ³n general en todas las transacciones    |
| **Precision** | 95%   | De las predichas como fraude, 95% son correctas |
| **Recall**    | 85%   | Detecta 85% de los fraudes reales               |
| **F1-Score**  | 90%   | Balance entre precisiÃ³n y cobertura             |
| **AUC-ROC**   | 0.95  | Excelente capacidad de discriminaciÃ³n           |

**Ventajas del enfoque**:

- âœ… Manejo efectivo de datos desbalanceados con SMOTE
- âœ… Alta precisiÃ³n minimiza falsos positivos costosos
- âœ… Buen recall para capturar la mayorÃ­a de fraudes
- âœ… Random Forest robusto ante ruido y outliers
- âœ… ValidaciÃ³n con conjunto separado sin balancear

**Consideraciones en producciÃ³n**:

- **Costo de falsos negativos**: Un fraude no detectado puede costar mÃ¡s que revisar falsos positivos
- **Threshold ajustable**: Se puede ajustar el umbral de decisiÃ³n segÃºn el costo del negocio
- **Monitoreo continuo**: Los patrones de fraude evolucionan, requiere reentrenamiento periÃ³dico

## ğŸ“ˆ Visualizaciones y AnÃ¡lisis

### Predictor de Casas

1. **AnÃ¡lisis de CaracterÃ­sticas** (`feature_analysis.png`)

   - DistribuciÃ³n de variables independientes
   - Correlaciones entre features y precio
   - DetecciÃ³n de outliers

2. **Predicciones del Modelo**
   - `predictions_vs_actual.png`: ComparaciÃ³n predicciones vs reales
   - `kaggle_predictions.png`: Resultados modelo Kaggle lineal
   - `kaggle_rf_predictions.png`: Resultados Random Forest Kaggle
   - LÃ­nea de regresiÃ³n ideal y distribuciÃ³n de errores

### Predictor de Titanic

1. **AnÃ¡lisis Exploratorio** (generado por `visualization.py`)

   - DistribuciÃ³n de supervivencia por clase, sexo, edad
   - AnÃ¡lisis de tarifas pagadas
   - Impacto del puerto de embarque
   - VisualizaciÃ³n de valores faltantes

2. **Feature Engineering**

   - CreaciÃ³n de `family_size` y `is_alone`
   - One-hot encoding de variables categÃ³ricas
   - ImputaciÃ³n inteligente de edad (mediana por clase/sexo)

3. **EvaluaciÃ³n del Modelo**
   - Matriz de confusiÃ³n detallada
   - Reporte de clasificaciÃ³n completo
   - AnÃ¡lisis de importancia de features

### DetecciÃ³n de Fraude

1. **AnÃ¡lisis Exploratorio de Datos** (EDA)

   - **DistribuciÃ³n de clases**: VisualizaciÃ³n del desbalance
   - **DistribuciÃ³n de montos**: ComparaciÃ³n fraude vs legÃ­timas
   - **AnÃ¡lisis temporal**: Patrones de fraude en el tiempo
   - **Correlaciones**: Heatmap de features V1-V28
   - **Boxplots**: DetecciÃ³n de outliers por clase

2. **Preprocesamiento y Balanceo**

   - VisualizaciÃ³n del efecto de SMOTE
   - ComparaciÃ³n distribuciones antes/despuÃ©s de balanceo
   - AnÃ¡lisis de splits (train/validation/test)

3. **EvaluaciÃ³n del Modelo**

   - **Matriz de confusiÃ³n**: Predicciones en conjunto de test
   - **Curva ROC**: AUC = 0.95
   - **Curva Precision-Recall**: Especialmente importante en datos desbalanceados
   - **Feature Importance**: Features mÃ¡s relevantes para detecciÃ³n
   - **DistribuciÃ³n de probabilidades**: SeparaciÃ³n entre clases

4. **Dashboard Interactivo** (Streamlit)
   - MÃ©tricas clave en tiempo real
   - Visualizaciones interactivas de rendimiento
   - AnÃ¡lisis de predicciones individuales
   - Explorador de datos con filtros
   - Analytics avanzado con insights del modelo

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Core ML Stack

- **Python 3.8+**: Lenguaje de programaciÃ³n principal
- **pandas**: ManipulaciÃ³n y anÃ¡lisis de datos
- **numpy**: ComputaciÃ³n numÃ©rica y Ã¡lgebra lineal
- **scikit-learn**: Algoritmos de machine learning (regresiÃ³n, clasificaciÃ³n, RF)
- **matplotlib**: VisualizaciÃ³n de datos y grÃ¡ficos
- **seaborn**: Visualizaciones estadÃ­sticas avanzadas

### Versiones EspecÃ­ficas

#### predictor-house

- `pandas==2.3.2`
- `numpy==2.3.3`
- `scikit-learn==1.7.2`
- `matplotlib==3.10.6`
- `jupyter==1.1.1`
- `streamlit==1.40.1`

#### predictor-titanic

- Versiones libres de pandas, numpy, matplotlib, seaborn, scikit-learn

#### fraude-detection

- `pandas`, `numpy`, `scikit-learn`
- `imbalanced-learn`: Para tÃ©cnicas de balanceo (SMOTE)
- `matplotlib`, `seaborn`, `plotly`: Visualizaciones
- `streamlit`: AplicaciÃ³n web multipÃ¡gina
- `jupyter`: Notebooks interactivos

### Herramientas de Desarrollo

- **pickle/joblib**: SerializaciÃ³n de modelos entrenados
- **Jupyter Notebooks**: ExploraciÃ³n interactiva de datos
- **Streamlit**: Aplicaciones web interactivas
- **Git/GitHub**: Control de versiones y colaboraciÃ³n
- **imbalanced-learn**: Balanceo de clases desbalanceadas

## ğŸ“ Conceptos de Machine Learning Aplicados

### TÃ©cnicas Implementadas

- **RegresiÃ³n Lineal MÃºltiple**: PredicciÃ³n de valores continuos (precios de casas)
- **Random Forest**:
  - Ensemble learning para clasificaciÃ³n binaria (Titanic, Fraude)
  - Mejora de regresiÃ³n lineal en datos Kaggle (House Prices)
  - Robusto ante datos desbalanceados y outliers
- **Feature Engineering**:
  - CreaciÃ³n de variables derivadas (family_size, is_alone)
  - AnÃ¡lisis de importancia de features
- **Data Preprocessing**:
  - Manejo de valores faltantes (mediana, moda, estrategias inteligentes)
  - Encoding de variables categÃ³ricas (LabelEncoder, One-Hot)
  - Feature scaling y normalizaciÃ³n
  - **TÃ©cnicas de balanceo**: SMOTE para datos altamente desbalanceados
- **Train/Test/Validation Split**: DivisiÃ³n estratificada de datos
- **Model Persistence**: SerializaciÃ³n con pickle/joblib
- **MÃ©tricas de EvaluaciÃ³n**:
  - RegresiÃ³n: RÂ², MAE, RMSE
  - ClasificaciÃ³n: Accuracy, Precision, Recall, F1-Score, AUC-ROC
  - Confusion Matrix y Classification Report

### DesafÃ­os Resueltos

#### ğŸ  Predictor de Casas

- **Multicolinealidad**: AnÃ¡lisis de correlaciones entre features
- **Overfitting**: ValidaciÃ³n con train/test split
- **Escalabilidad**: Tres versiones (simple, Kaggle lineal, Kaggle RF)

#### ğŸš¢ Predictor de Titanic

- **Datos faltantes**: ImputaciÃ³n inteligente por grupos
- **Features categÃ³ricas**: Encoding apropiado
- **Feature engineering**: CreaciÃ³n de variables significativas
- **Interpretabilidad**: AnÃ¡lisis de feature importance

#### ğŸ’³ DetecciÃ³n de Fraude

- **Datos altamente desbalanceados**: 99.83% vs 0.17%
  - SoluciÃ³n: SMOTE para generar muestras sintÃ©ticas de la clase minoritaria
- **Alta dimensionalidad**: 30 features (28 de PCA)
  - SoluciÃ³n: Random Forest maneja bien alta dimensionalidad
- **Costo asimÃ©trico de errores**:
  - Falso negativo (fraude no detectado) es mÃ¡s costoso que falso positivo
  - SoluciÃ³n: OptimizaciÃ³n de threshold y mÃ©tricas enfocadas en recall
- **GeneralizaciÃ³n**:
  - ValidaciÃ³n en conjunto sin balancear para simular producciÃ³n
  - Monitoreo de mÃ©tricas en datos reales
- **Interpretabilidad**:
  - Feature importance para entender patrones de fraude
  - Visualizaciones de distribuciones por clase

### Buenas PrÃ¡cticas Aplicadas

âœ… **Arquitectura Modular**: SeparaciÃ³n clara de responsabilidades (carga, preprocesamiento, modelo, visualizaciÃ³n)  
âœ… **ConfiguraciÃ³n Centralizada**: `config.py` con rutas absolutas y parÃ¡metros  
âœ… **Reproducibilidad**: `random_state` fijo para splits y modelos  
âœ… **Pandas 3.0 Ready**: Evita chained assignment con `inplace=True`  
âœ… **Logging Descriptivo**: Prints formateados con emojis y separadores  
âœ… **Persistencia de Modelos**: Guardado/carga con pickle/joblib para reutilizaciÃ³n  
âœ… **DocumentaciÃ³n**: READMEs detallados e instrucciones para agentes IA  
âœ… **ValidaciÃ³n Realista**: En fraude-detection, validaciÃ³n en datos sin balancear  
âœ… **MÃºltiples Notebooks**: SeparaciÃ³n de anÃ¡lisis, preprocesamiento, entrenamiento y evaluaciÃ³n

## ğŸ‘¨â€ğŸ’» Autor y PropÃ³sito

**Deep Learning Repository** - ColecciÃ³n educativa de proyectos de Machine Learning

Este repositorio fue creado con fines educativos para demostrar:

- ImplementaciÃ³n end-to-end de proyectos de ML (regresiÃ³n, clasificaciÃ³n, detecciÃ³n de anomalÃ­as)
- Arquitectura modular y escalable
- Buenas prÃ¡cticas de desarrollo en Data Science
- Manejo de diferentes tipos de problemas:
  - **RegresiÃ³n**: PredicciÃ³n de valores continuos
  - **ClasificaciÃ³n balanceada**: Datos con distribuciÃ³n similar entre clases
  - **ClasificaciÃ³n desbalanceada**: DetecciÃ³n de eventos raros con tÃ©cnicas de balanceo
- Pipeline completo desde datos crudos hasta aplicaciones web interactivas
- AplicaciÃ³n de tÃ©cnicas avanzadas (SMOTE, feature engineering, hyperparameter tuning)

### ğŸ“š Recursos Educativos

- **Kaggle Competitions**:
  - [House Prices - Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
  - [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- **Datasets pÃºblicos**:
  - Titanic incluido en Seaborn (`sns.load_dataset('titanic')`)
- **Instrucciones IA**: `.github/copilot-instructions.md` para agentes de desarrollo

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia **MIT**. Ver el archivo [`LICENSE`](LICENSE) para mÃ¡s detalles.

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Para contribuir:

1. Fork del repositorio
2. Crear rama feature (`git checkout -b feature/nueva-caracteristica`)
3. Commit de cambios (`git commit -am 'AÃ±adir nueva caracterÃ­stica'`)
4. Push a la rama (`git push origin feature/nueva-caracteristica`)
5. Crear Pull Request

**GuÃ­as de contribuciÃ³n**:

- Seguir la estructura modular existente
- Actualizar READMEs si se aÃ±aden features
- Mantener compatibilidad con pandas 3.0 (evitar chained assignment)
- Documentar funciones y aÃ±adir prints descriptivos

---

**Â¿Tienes preguntas?** Abre un [issue](https://github.com/devlitus/repos-deep-learning/issues) en el repositorio.

---

<div align="center">

Hecho con â¤ï¸ para la comunidad de Data Science

[![Star on GitHub](https://img.shields.io/github/stars/devlitus/repos-deep-learning?style=social)](https://github.com/devlitus/repos-deep-learning)

</div>

## ğŸ“ PrÃ³ximas Mejoras

### Predictor de Casas

- [ ] ValidaciÃ³n cruzada (k-fold CV)
- [ ] Hyperparameter tuning (GridSearchCV)
- [ ] MÃ¡s algoritmos (XGBoost, Gradient Boosting)
- [ ] API REST con FastAPI
- [ ] Dashboard avanzado con Plotly/Dash
- [ ] Feature importance analysis
- [ ] DetecciÃ³n automÃ¡tica de outliers

### Predictor de Titanic

- [ ] ComparaciÃ³n con otros clasificadores (SVM, Gradient Boosting)
- [ ] OptimizaciÃ³n de hiperparÃ¡metros Random Forest
- [ ] Feature engineering avanzado (tÃ­tulos en nombres, cabinas)
- [ ] AnÃ¡lisis de SHAP values
- [ ] Cross-validation para robustez
- [ ] Deployment como servicio web

### DetecciÃ³n de Fraude

- [x] Pipeline completo de preprocesamiento
- [x] ImplementaciÃ³n de SMOTE para balanceo
- [x] AplicaciÃ³n web Streamlit multipÃ¡gina
- [x] 4 notebooks Jupyter documentados
- [x] Persistencia de datos procesados
- [ ] ComparaciÃ³n con otros modelos (XGBoost, LightGBM, Neural Networks)
- [ ] Hyperparameter tuning con RandomizedSearchCV
- [ ] AnÃ¡lisis de SHAP values para interpretabilidad
- [ ] DetecciÃ³n de concept drift y reentrenamiento automÃ¡tico
- [ ] API REST para integraciÃ³n en sistemas de producciÃ³n
- [ ] Sistema de alertas en tiempo real
- [ ] AnÃ¡lisis de series temporales de fraude
- [ ] Feature engineering avanzado sobre features PCA
- [ ] Ensemble methods (stacking, voting)
- [ ] Monitoreo de performance en producciÃ³n

### General

- [ ] Tests unitarios completos (pytest)
- [ ] CI/CD pipeline con GitHub Actions
- [ ] DockerizaciÃ³n de los tres proyectos
- [ ] Notebooks Jupyter documentados (completo en fraude-detection)
- [ ] Logging avanzado con `logging` module
- [ ] DocumentaciÃ³n con MkDocs o Sphinx
- [ ] IntegraciÃ³n con MLflow para tracking de experimentos
