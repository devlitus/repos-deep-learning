# ğŸ§  Deep Learning Repository - Proyectos de Machine Learning

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.7.2-orange.svg)](https://scikit-learn.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![GitHub repo](https://img.shields.io/badge/GitHub-repos--deep--learning-181717?logo=github)](https://github.com/devlitus/repos-deep-learning)

Repositorio educativo con **cuatro proyectos independientes de Machine Learning** siguiendo arquitectura modular y mejores prÃ¡cticas:

- ğŸ  **Predictor de Precios de Casas**: RegresiÃ³n lineal mÃºltiple para estimar precios inmobiliarios
- ğŸš¢ **Predictor de Supervivencia del Titanic**: ClasificaciÃ³n binaria con Random Forest
- ğŸ’³ **DetecciÃ³n de Fraude**: Sistema avanzado de detecciÃ³n de transacciones fraudulentas con tÃ©cnicas de balanceo
- ğŸŒ¡ï¸ **PredicciÃ³n de Temperatura**: Series temporales con redes neuronales LSTM (prediction-temperature)

Cada proyecto incluye pipeline completo: carga de datos â†’ preprocesamiento â†’ entrenamiento â†’ evaluaciÃ³n â†’ predicciones.

## ğŸš€ GuÃ­a RÃ¡pida

### Â¿Eres principiante en ML?

- ğŸ  **Empieza con `predictor-house/`**: RegresiÃ³n simple y conceptos bÃ¡sicos
- ğŸ“š Lee los notebooks de `fraude-detection/notebooks/` para anÃ¡lisis paso a paso

### Â¿Buscas un desafÃ­o tÃ©cnico?

- ğŸ’³ **`fraude-detection/`**: Datos desbalanceados, SMOTE y producciÃ³n
- ğŸš¢ **`predictor-titanic/`**: Feature engineering y clasificaciÃ³n avanzada

### Â¿Quieres ver aplicaciones web?

- ğŸ  `predictor-house/app.py` - PredicciÃ³n de precios interactiva
- ğŸ’³ `fraude-detection/web/app.py` - Dashboard completo de detecciÃ³n de fraude

### Â¿Interesado en Deep Learning?

- ğŸŒ¡ï¸ **`prediction-temperature/`**: Redes neuronales LSTM para series temporales
  - PredicciÃ³n de temperaturas con datos histÃ³ricos (10 aÃ±os)
  - ComparaciÃ³n con implementaciÃ³n clÃ¡sica
  - MÃ©tricas de error para evaluaciÃ³n temporal

### Â¿Solo quieres ejecutar algo rÃ¡pido?

```bash
# Proyecto mÃ¡s simple
cd predictor-house && python main.py

# Proyecto con mejor visualizaciÃ³n
cd fraude-detection && streamlit run web/app.py

# AnÃ¡lisis completo con notebooks
cd fraude-detection && jupyter notebook notebooks/

# Deep learning con series temporales
cd prediction-temperature && python main.py
```

## ğŸ¯ Proyectos Incluidos

### ğŸ  Predictor de Precios de Casas (`predictor-house/`)

**Tipo**: RegresiÃ³n Lineal MÃºltiple  
**Dataset**: Kaggle House Prices + Dataset sintÃ©tico local  
**Objetivo**: Predecir precios de viviendas basÃ¡ndose en caracterÃ­sticas fÃ­sicas y ubicaciÃ³n

**CaracterÃ­sticas clave**:

- ğŸ“Š AnÃ¡lisis de 5 variables: tamaÃ±o, habitaciones, baÃ±os, edad, distancia al centro
- ğŸ“ˆ RegresiÃ³n lineal con scikit-learn
- ğŸ¨ Visualizaciones de correlaciones y predicciones
- ğŸ”® Sistema de predicciÃ³n para nuevas propiedades
- ğŸ“¦ Tres implementaciones: modelo simple, Kaggle lineal, Kaggle Random Forest

**MÃ©tricas de evaluaciÃ³n**: RÂ² Score, MAE, RMSE

### ğŸš¢ Predictor de Supervivencia del Titanic (`predictor-titanic/`)

**Tipo**: ClasificaciÃ³n Binaria  
**Dataset**: Titanic dataset (Seaborn)  
**Objetivo**: Predecir supervivencia de pasajeros del Titanic

**CaracterÃ­sticas clave**:

- ğŸ« AnÃ¡lisis de 7 features: clase, sexo, edad, tarifa, embarque, familia
- ğŸŒ² Random Forest Classifier
- ğŸ§¹ Pipeline robusto de preprocesamiento (manejo de nulos, encoding)
- ğŸ“Š Visualizaciones exploratorias detalladas
- ğŸ¯ Feature engineering (family_size, is_alone)

**MÃ©tricas de evaluaciÃ³n**: Accuracy, Precision, Recall, F1-Score, Matriz de confusiÃ³n

### ğŸ’³ DetecciÃ³n de Fraude en Tarjetas de CrÃ©dito (`fraude-detection/`)

**Tipo**: ClasificaciÃ³n Binaria con Datos Desbalanceados  
**Dataset**: Credit Card Fraud Detection (Kaggle)  
**Objetivo**: Identificar transacciones fraudulentas en tiempo real

**CaracterÃ­sticas clave**:

- ğŸ¯ **Datos altamente desbalanceados**: <0.2% de fraudes en el dataset
- âš–ï¸ **TÃ©cnicas de balanceo**: SMOTE (Synthetic Minority Oversampling Technique)
- ğŸŒ² Random Forest optimizado para detecciÃ³n de anomalÃ­as
- ğŸ“Š AnÃ¡lisis exploratorio completo con 4 notebooks interactivos
- ğŸŒ **AplicaciÃ³n web Streamlit** con mÃºltiples pÃ¡ginas:
  - Dashboard principal con mÃ©tricas clave
  - PredicciÃ³n de transacciones individuales
  - AnÃ¡lisis de datos exploratorio
  - Analytics avanzado con visualizaciones
- ğŸ”„ Pipeline completo: EDA â†’ Preprocesamiento â†’ Balanceo â†’ Entrenamiento â†’ EvaluaciÃ³n
- ğŸ’¾ Persistencia de datos procesados y splits para reproducibilidad

**MÃ©tricas de evaluaciÃ³n**: Accuracy (~99.9%), Precision (95%), Recall (85%), F1-Score (90%), AUC-ROC (0.95)

### ğŸŒ¡ï¸ PredicciÃ³n de Temperatura (`prediction-temperature/`)

**Tipo**: RegresiÃ³n de Series Temporales con Deep Learning
**Dataset**: Temperaturas mÃ­nimas diarias de Melbourne (1981-1990)
**Objetivo**: Predecir temperaturas futuras usando datos histÃ³ricos

**CaracterÃ­sticas clave**:

- ğŸ§  **Red Neuronal LSTM**: 3 capas para capturar dependencias temporales
- ğŸ“Š **Datos de series temporales**: 10 aÃ±os de temperaturas diarias (3,650 muestras)
- ğŸ¯ **NormalizaciÃ³n**: Escalamiento MinMax para redes neuronales
- ğŸ“ˆ **Visualizaciones temporales**: Predicciones vs valores reales en el tiempo
- ğŸ’¾ **Persistencia**: Modelos guardados en formato Keras (.keras)
- ğŸ“‹ **MÃ©tricas especializadas**: MAE, RMSE para evaluaciÃ³n temporal

**ComparaciÃ³n clÃ¡sica vs Deep Learning**:

- ImplementaciÃ³n de modelo clÃ¡sico (baseline)
- ComparaciÃ³n de rendimiento LSTM vs mÃ©todos tradicionales
- AnÃ¡lisis de errores en diferentes perÃ­odos del aÃ±o

**MÃ©tricas de evaluaciÃ³n**: MAE, RMSE, Error Porcentual Medio

## ï¿½ ComparaciÃ³n de Proyectos

| CaracterÃ­stica        | ğŸ  Predictor Casas | ğŸš¢ Predictor Titanic     | ğŸ’³ DetecciÃ³n Fraude          | ğŸŒ¡ï¸ PredicciÃ³n Temperatura   |
| --------------------- | ------------------ | ------------------------ | ---------------------------- | ------------------------------ |
| **Tipo de ML**        | RegresiÃ³n          | ClasificaciÃ³n Balanceada | ClasificaciÃ³n Desbalanceada  | Series Temporales (LSTM)       |
| **Dataset**           | SintÃ©tico + Kaggle | Seaborn (Titanic)        | Kaggle (284K transacciones)  | Melbourne (10 aÃ±os)            |
| **Dificultad**        | â­â­               | â­â­â­                   | â­â­â­â­                     | â­â­â­â­â­                   |
| **TamaÃ±o Dataset**    | PequeÃ±o            | Mediano                  | Grande                       | Mediano (3,650 muestras)       |
| **DesafÃ­o Principal** | Multicolinealidad  | Datos faltantes          | Datos desbalanceados (0.17%) | Dependencias temporales        |
| **TÃ©cnicas Clave**    | RegresiÃ³n lineal   | Feature engineering      | SMOTE, balanceo              | LSTM, normalizaciÃ³n            |
| **AplicaciÃ³n Web**    | Streamlit simple   | Sin web                  | Streamlit multipÃ¡gina        | Visualizaciones temporales     |
| **Framework ML**      | scikit-learn       | scikit-learn             | scikit-learn + imbalanced    | TensorFlow/Keras               |
| **Notebooks**         | 1 opcional         | 1 bÃ¡sico                 | 4 completos                  | AnÃ¡lisis y comparaciÃ³n         |
| **Estado**            | âœ… Completo        | âœ… Completo              | âœ… Completo                  | âœ… Completo                    |

## ï¿½ğŸ“ Estructura del Repositorio

```
repos-deep-learning/
â”‚
â”œâ”€â”€ predictor-house/           # ğŸ  Proyecto de RegresiÃ³n (Precios Casas)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/              # Datos originales (casas.csv + Kaggle datasets)
â”‚   â”‚   â””â”€â”€ processed/        # Datos procesados
â”‚   â”œâ”€â”€ src/                  # MÃ³dulos Python
â”‚   â”‚   â”œâ”€â”€ data_loader.py    # Carga y exploraciÃ³n
â”‚   â”‚   â”œâ”€â”€ model.py          # Entrenamiento/evaluaciÃ³n
â”‚   â”‚   â”œâ”€â”€ predictor.py      # Predicciones
â”‚   â”‚   â”œâ”€â”€ visualizations.py # GrÃ¡ficos
â”‚   â”‚   â””â”€â”€ explore_kaggle.py # AnÃ¡lisis Kaggle dataset
â”‚   â”œâ”€â”€ models/               # Modelos entrenados (.pkl)
â”‚   â”‚   â”œâ”€â”€ modelo_casas.pkl
â”‚   â”‚   â”œâ”€â”€ modelo_kaggle.pkl
â”‚   â”‚   â””â”€â”€ modelo_kaggle_rf.pkl
â”‚   â”œâ”€â”€ reports/figures/      # Visualizaciones generadas
â”‚   â”œâ”€â”€ main.py               # Pipeline principal
â”‚   â”œâ”€â”€ main_kaggle.py        # Pipeline Kaggle (regresiÃ³n lineal)
â”‚   â”œâ”€â”€ main_kaggle_rf.py     # Pipeline Kaggle (Random Forest)
â”‚   â”œâ”€â”€ app.py                # AplicaciÃ³n Streamlit
â”‚   â”œâ”€â”€ config.py             # Configuraciones del proyecto
â”‚   â””â”€â”€ requirements.txt      # Dependencias especÃ­ficas
â”‚
â”œâ”€â”€ predictor-titanic/         # ğŸš¢ Proyecto de ClasificaciÃ³n (Titanic)
â”‚   â”œâ”€â”€ data/                 # (Dataset cargado desde seaborn)
â”‚   â”œâ”€â”€ src/                  # MÃ³dulos Python
â”‚   â”‚   â”œâ”€â”€ data_loader.py    # Carga dataset Titanic
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py  # Limpieza y feature engineering
â”‚   â”‚   â”œâ”€â”€ model.py          # Entrenamiento Random Forest
â”‚   â”‚   â”œâ”€â”€ visualization.py  # AnÃ¡lisis exploratorio
â”‚   â”‚   â””â”€â”€ predictor.py      # Predicciones
â”‚   â”œâ”€â”€ models/               # Modelos entrenados
â”‚   â”‚   â””â”€â”€ titanic_random_forest.pkl
â”‚   â”œâ”€â”€ reports/              # Reportes y visualizaciones
â”‚   â”œâ”€â”€ config.py             # Configuraciones del proyecto
â”‚   â”œâ”€â”€ main.py               # Pipeline completo
â”‚   â””â”€â”€ requirements.txt      # Dependencias especÃ­ficas
â”‚
â”œâ”€â”€ fraude-detection/          # ğŸ’³ Proyecto de DetecciÃ³n de Fraude
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/              # creditcard.csv (Kaggle)
â”‚   â”‚   â””â”€â”€ processed/        # Datos procesados y splits
â”‚   â”‚       â”œâ”€â”€ X_train_original.csv
â”‚   â”‚       â”œâ”€â”€ X_train_balanced.csv
â”‚   â”‚       â”œâ”€â”€ X_val.csv
â”‚   â”‚       â”œâ”€â”€ X_test.csv
â”‚   â”‚       â””â”€â”€ y_*.csv
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”œâ”€â”€ load.py       # Carga de datos
â”‚   â”‚   â”‚   â””â”€â”€ preprocess.py # Preprocesamiento y balanceo
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py      # Entrenamiento de modelos
â”‚   â”‚   â”‚   â””â”€â”€ evaluate.py   # EvaluaciÃ³n y mÃ©tricas
â”‚   â”‚   â””â”€â”€ visualization/
â”‚   â”‚       â””â”€â”€ plots.py      # GrÃ¡ficos y visualizaciones
â”‚   â”œâ”€â”€ web/                  # AplicaciÃ³n Streamlit multipÃ¡gina
â”‚   â”‚   â”œâ”€â”€ app.py            # App principal
â”‚   â”‚   â”œâ”€â”€ pages/            # PÃ¡ginas individuales
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prediction.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_explorer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics.py
â”‚   â”‚   â”‚   â””â”€â”€ about.py
â”‚   â”‚   â”œâ”€â”€ styles/           # CSS personalizado
â”‚   â”‚   â””â”€â”€ utils/            # Utilidades web
â”‚   â”œâ”€â”€ notebooks/            # 4 notebooks Jupyter
â”‚   â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â”‚   â””â”€â”€ 04_model_evaluation.ipynb
â”‚   â”œâ”€â”€ models/               # Modelos y reportes
â”‚   â”‚   â”œâ”€â”€ final_evaluation_report.csv
â”‚   â”‚   â”œâ”€â”€ final_evaluation_report.json
â”‚   â”‚   â””â”€â”€ model_metrics.csv
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.py         # Configuraciones centralizadas
â”‚   â”œâ”€â”€ main.py               # Pipeline completo
â”‚   â”œâ”€â”€ verify_installation.py # VerificaciÃ³n de setup
â”‚   â””â”€â”€ requirements.txt      # Dependencias especÃ­ficas
â”‚
â”œâ”€â”€ prediction-temperature/    # ğŸŒ¡ï¸ Proyecto de Series Temporales (LSTM)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/              # daily-min-temperatures.csv (10 aÃ±os)
â”‚   â”‚   â””â”€â”€ processed/        # Datos normalizados y secuencias
â”‚   â”œâ”€â”€ src/                  # MÃ³dulos Python
â”‚   â”‚   â”œâ”€â”€ data_loader.py    # Carga y exploraciÃ³n datos temporales
â”‚   â”‚   â”œâ”€â”€ model.py          # Entrenamiento LSTM
â”‚   â”‚   â”œâ”€â”€ classic_model.py  # Modelo clÃ¡sico (baseline)
â”‚   â”‚   â”œâ”€â”€ predictor.py      # Predicciones futuras
â”‚   â”‚   â””â”€â”€ visualizations.py # GrÃ¡ficos temporales
â”‚   â”œâ”€â”€ models/               # Modelos entrenados (.keras)
â”‚   â”‚   â”œâ”€â”€ lstm_temperatura.keras
â”‚   â”‚   â””â”€â”€ classic_model.pkl
â”‚   â”œâ”€â”€ reports/              # Visualizaciones y mÃ©tricas
â”‚   â”‚   â”œâ”€â”€ entrenamiento.png
â”‚   â”‚   â”œâ”€â”€ predicciones.png
â”‚   â”‚   â”œâ”€â”€ metricas.txt
â”‚   â”‚   â””â”€â”€ scatter.png
â”‚   â”œâ”€â”€ notebooks/            # Jupyter notebooks (anÃ¡lisis y comparaciÃ³n)
â”‚   â”œâ”€â”€ config.py             # Configuraciones del proyecto
â”‚   â”œâ”€â”€ main.py               # Pipeline completo
â”‚   â””â”€â”€ requirements.txt      # Dependencias especÃ­ficas (TensorFlow, Keras)
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md  # Instrucciones para agentes IA
â”œâ”€â”€ LICENSE                   # Licencia MIT
â””â”€â”€ README.md                 # Este archivo
```

### ğŸ—‚ï¸ PatrÃ³n de Arquitectura ComÃºn

Los proyectos siguen una estructura modular consistente:

- **`config.py`**: Rutas absolutas, features, hiperparÃ¡metros
- **`src/data_loader.py`**: Carga de datos desde fuentes locales/remotas
- **`src/model.py` o `train_model.py`**: Entrenamiento y evaluaciÃ³n
- **`src/visualizations.py`**: GeneraciÃ³n de grÃ¡ficos analÃ­ticos
- **`main.py`**: Pipeline completo ejecutable
- **`models/`**: Persistencia de modelos con pickle

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- Git (para clonar el repositorio)

### InstalaciÃ³n General

1. **Clonar el repositorio**

   ```powershell
   git clone https://github.com/devlitus/repos-deep-learning.git
   cd repos-deep-learning
   ```

2. **Crear entorno virtual (recomendado)**

   ```powershell
   python -m venv venv
   # Activar en Windows PowerShell
   .\venv\Scripts\Activate.ps1
   ```

### ğŸ  Ejecutar Predictor de Casas

```powershell
cd predictor-house
pip install -r requirements.txt
python main.py              # Pipeline con dataset simple
python main_kaggle.py       # Pipeline Kaggle (regresiÃ³n lineal)
python main_kaggle_rf.py    # Pipeline Kaggle (Random Forest)
streamlit run app.py        # AplicaciÃ³n web interactiva
```

**Output esperado**:

- Modelo entrenado en `models/modelo_casas.pkl`
- Visualizaciones en `reports/figures/`
- MÃ©tricas de evaluaciÃ³n en consola

### ğŸš¢ Ejecutar Predictor de Titanic

```powershell
cd predictor-titanic
pip install -r requirements.txt
python main.py              # Pipeline completo
```

**Output esperado**:

- Modelo Random Forest en `models/titanic_random_forest.pkl`
- AnÃ¡lisis detallado con prints formateados
- Matriz de confusiÃ³n y mÃ©tricas de clasificaciÃ³n

### ğŸ’³ Ejecutar DetecciÃ³n de Fraude

```powershell
cd fraude-detection
pip install -r requirements.txt

# Verificar instalaciÃ³n
python verify_installation.py

# Ejecutar pipeline completo
python main.py

# Lanzar aplicaciÃ³n web
streamlit run web/app.py

# Explorar notebooks
jupyter notebook notebooks/
```

**Output esperado**:

- Datos procesados en `data/processed/` (splits originales y balanceados)
- Modelos entrenados y mÃ©tricas en `models/`
- Reportes JSON en `reports/eda_insights.json`
- AplicaciÃ³n web interactiva en `http://localhost:8501`

### ğŸŒ¡ï¸ Ejecutar PredicciÃ³n de Temperatura

```powershell
cd prediction-temperature
pip install -r requirements.txt

# Ejecutar pipeline completo (LSTM + modelo clÃ¡sico)
python main.py

# Explorar notebooks
jupyter notebook notebooks/
```

**Output esperado**:

- Modelos entrenados en `models/` (LSTM .keras y modelo clÃ¡sico .pkl)
- Visualizaciones en `reports/` (grÃ¡ficos de entrenamiento y predicciones)
- MÃ©tricas de evaluaciÃ³n en consola (MAE, RMSE)
- ComparaciÃ³n de rendimiento LSTM vs modelo clÃ¡sico

## ğŸ“Š Ejemplos de Uso

### ğŸ  Predicciones de Precios de Casas

```python
import pickle
from src.predictor import predict_new_houses

# Cargar modelo entrenado
with open('predictor-house/models/modelo_casas.pkl', 'rb') as f:
    modelo = pickle.load(f)

# Formato: [tamaÃ±o_m2, habitaciones, baÃ±os, edad_aÃ±os, distancia_centro_km]
casas_nuevas = [
    [130, 3, 2, 10, 5.0],  # Casa mediana
    [200, 5, 4, 1, 2.0],   # Casa grande y nueva
]

predict_new_houses(modelo, casas_nuevas)
```

### ğŸš¢ AnÃ¡lisis de Supervivencia del Titanic

```python
import joblib
import pandas as pd

# Cargar modelo
modelo = joblib.load('predictor-titanic/models/titanic_random_forest.pkl')

# Ejemplo de pasajero
pasajero = pd.DataFrame({
    'pclass': [1],           # Primera clase
    'sex': [0],              # Mujer (codificado)
    'age': [28],             # 28 aÃ±os
    'fare': [80],            # Tarifa pagada
    'embarked': [0],         # Cherbourg
    'family_size': [2],      # Viaja con 1 familiar
    'is_alone': [0]          # No viaja solo
})

prediccion = modelo.predict(pasajero)
probabilidad = modelo.predict_proba(pasajero)
print(f"Supervivencia: {'âœ… SobreviviÃ³' if prediccion[0] else 'âŒ No sobreviviÃ³'}")
print(f"Probabilidad: {probabilidad[0][1]:.2%}")
```

### ğŸ’³ DetecciÃ³n de Transacciones Fraudulentas

```python
import joblib
import pandas as pd
import numpy as np

# Cargar modelo entrenado
modelo = joblib.load('fraude-detection/models/fraud_detection_model.pkl')

# Ejemplo de transacciÃ³n (features V1-V28 + Amount)
# En producciÃ³n, estas features vienen de PCA del dataset original
transaccion = pd.DataFrame({
    'V1': [-1.359807],
    'V2': [-0.072781],
    # ... V3 a V27 ...
    'V28': [0.014724],
    'Amount': [149.62],
    'Time': [0]
})

# Predecir
prediccion = modelo.predict(transaccion)
probabilidad = modelo.predict_proba(transaccion)

if prediccion[0] == 1:
    print(f"âš ï¸ FRAUDE DETECTADO - Confianza: {probabilidad[0][1]:.2%}")
else:
    print(f"âœ… TransacciÃ³n legÃ­tima - Confianza: {probabilidad[0][0]:.2%}")
```

### ğŸŒ¡ï¸ PredicciÃ³n de Temperaturas con LSTM

```python
import tensorflow as tf
import numpy as np
from sklearn.preprocessing import MinMaxScaler

# Cargar modelo LSTM entrenado
modelo_lstm = tf.keras.models.load_model('prediction-temperature/models/lstm_temperatura.keras')

# Datos histÃ³ricos normalizados (Ãºltimos 60 dÃ­as)
# En producciÃ³n, estos datos vienen del dataset procesado
datos_historicos = np.array([[15.2], [15.5], [16.1], [15.8], ...])  # 60 dÃ­as
scaler = MinMaxScaler(feature_range=(0, 1))
datos_normalizados = scaler.fit_transform(datos_historicos)

# Preparar entrada para el modelo (reshape para LSTM: (1, 60, 1))
entrada = datos_normalizados.reshape(1, 60, 1)

# Predecir siguiente temperatura
temperatura_normalizada = modelo_lstm.predict(entrada)
temperatura_predicha = scaler.inverse_transform(temperatura_normalizada)

print(f"ğŸŒ¡ï¸ Temperatura predicha para maÃ±ana: {temperatura_predicha[0][0]:.1f}Â°C")

# Predecir prÃ³ximos 30 dÃ­as
for i in range(30):
    temperatura_normalizada = modelo_lstm.predict(entrada)
    entrada = np.append(entrada[:, 1:, :], temperatura_normalizada.reshape(1, 1, 1), axis=1)
    temp_real = scaler.inverse_transform(temperatura_normalizada)
    print(f"DÃ­a {i+1}: {temp_real[0][0]:.1f}Â°C")
```

## ğŸ“‹ Datasets Utilizados

### Predictor de Casas

| Variable              | DescripciÃ³n                | Tipo     | Rango       |
| --------------------- | -------------------------- | -------- | ----------- |
| `tamano_m2`           | Superficie en mÂ²           | NumÃ©rico | 70-200 mÂ²   |
| `habitaciones`        | NÃºmero de habitaciones     | Entero   | 1-5         |
| `banos`               | NÃºmero de baÃ±os            | Entero   | 1-4         |
| `edad_anos`           | AntigÃ¼edad de la propiedad | Entero   | 1-30 aÃ±os   |
| `distancia_centro_km` | Distancia al centro        | Decimal  | 1.8-18.0 km |
| `precio` ğŸ¯           | Precio (target)            | NumÃ©rico | $145K-$620K |

**Fuentes**:

- Dataset sintÃ©tico local (`casas.csv`)
- Kaggle House Prices Competition (`train.csv`, `test.csv`)

### Predictor de Titanic

| Variable      | DescripciÃ³n                 | Tipo       | Valores        |
| ------------- | --------------------------- | ---------- | -------------- |
| `pclass`      | Clase del ticket            | CategÃ³rico | 1, 2, 3        |
| `sex`         | Sexo del pasajero           | CategÃ³rico | male, female   |
| `age`         | Edad del pasajero           | NumÃ©rico   | 0.42-80 aÃ±os   |
| `fare`        | Tarifa pagada               | NumÃ©rico   | $0-$512        |
| `embarked`    | Puerto de embarque          | CategÃ³rico | C, Q, S        |
| `family_size` | TamaÃ±o familia (engineered) | Entero     | 1-11           |
| `is_alone`    | Viaja solo (engineered)     | Binario    | 0, 1           |
| `survived` ğŸ¯ | Supervivencia (target)      | Binario    | 0 (No), 1 (SÃ­) |

**Fuente**: Seaborn dataset (`sns.load_dataset('titanic')`)

### DetecciÃ³n de Fraude

| Variable     | DescripciÃ³n                        | Tipo     | Valores        |
| ------------ | ---------------------------------- | -------- | -------------- |
| `Time`       | Segundos desde primera transacciÃ³n | NumÃ©rico | 0-172,792      |
| `V1` - `V28` | Features de PCA (anÃ³nimas)         | NumÃ©rico | Normalizados   |
| `Amount`     | Monto de la transacciÃ³n            | NumÃ©rico | $0-$25,691     |
| `Class` ğŸ¯   | Fraude (target)                    | Binario  | 0 (No), 1 (SÃ­) |

**CaracterÃ­sticas del dataset**:

- **Total transacciones**: 284,807
- **Transacciones fraudulentas**: 492 (0.172%)
- **Desbalance**: 99.83% legÃ­timas vs 0.17% fraudes
- **Features**: 30 (28 de PCA + Time + Amount)
- **Fuente**: Kaggle Credit Card Fraud Detection

**TÃ©cnicas de balanceo aplicadas**:

- SMOTE (Synthetic Minority Oversampling Technique)
- Ratio de balanceo: 0.5 (50% minoritaria vs mayoritaria)

### PredicciÃ³n de Temperatura

| Variable      | DescripciÃ³n                    | Tipo     | Rango        |
| ------------- | ------------------------------ | -------- | ------------ |
| `Date`        | Fecha de la observaciÃ³n        | Fecha    | 1981-1990    |
| `Temp_min` ğŸ¯ | Temperatura mÃ­nima (target)    | NumÃ©rico | 2Â°C - 21Â°C   |

**CaracterÃ­sticas del dataset**:

- **Total observaciones**: 3,650 dÃ­as (10 aÃ±os completos)
- **PerÃ­odo**: 1981-01-01 a 1990-12-31
- **Periodicidad**: Diaria
- **Valores faltantes**: Muy pocos (datos limpios)
- **Fuente**: UCI Machine Learning Repository
- **Procesamiento**: NormalizaciÃ³n MinMax (0-1) para redes neuronales
- **SecuenciaciÃ³n**: Ventanas de 60 dÃ­as para predicciÃ³n LSTM

**DesafÃ­os abordados**:

- Capturar patrones estacionales (variaciÃ³n anual)
- Dependencias temporales a largo plazo
- NormalizaciÃ³n apropiada para redes neuronales

## ğŸ”¬ Rendimiento de los Modelos

### ğŸ  Predictor de Casas

#### Modelo Simple (RegresiÃ³n Lineal)

- **RÂ² Score**: Coeficiente de determinaciÃ³n
- **MAE**: Error absoluto medio en dÃ³lares
- **RMSE**: RaÃ­z del error cuadrÃ¡tico medio
- **Visualizaciones**: Predicciones vs valores reales

#### Modelo Kaggle Random Forest

- **Mejora significativa** sobre regresiÃ³n lineal simple
- **Tres implementaciones** para comparaciÃ³n de rendimiento
- **ExportaciÃ³n de predicciones** para submission en Kaggle

### ğŸš¢ Predictor de Titanic

#### Random Forest Classifier

- **Accuracy**: PrecisiÃ³n general del modelo
- **Precision/Recall**: Por clase (sobreviviÃ³/no sobreviviÃ³)
- **F1-Score**: Media armÃ³nica de precision y recall
- **Matriz de ConfusiÃ³n**: VisualizaciÃ³n de predicciones correctas/incorrectas
- **Feature Importance**: Variables mÃ¡s relevantes para la predicciÃ³n

### ğŸ’³ DetecciÃ³n de Fraude

#### Random Forest Optimizado con SMOTE

| MÃ©trica       | Valor | DescripciÃ³n                                     |
| ------------- | ----- | ----------------------------------------------- |
| **Accuracy**  | 99.9% | PrecisiÃ³n general en todas las transacciones    |
| **Precision** | 95%   | De las predichas como fraude, 95% son correctas |
| **Recall**    | 85%   | Detecta 85% de los fraudes reales               |
| **F1-Score**  | 90%   | Balance entre precisiÃ³n y cobertura             |
| **AUC-ROC**   | 0.95  | Excelente capacidad de discriminaciÃ³n           |

**Ventajas del enfoque**:

- âœ… Manejo efectivo de datos desbalanceados con SMOTE
- âœ… Alta precisiÃ³n minimiza falsos positivos costosos
- âœ… Buen recall para capturar la mayorÃ­a de fraudes
- âœ… Random Forest robusto ante ruido y outliers
- âœ… ValidaciÃ³n con conjunto separado sin balancear

**Consideraciones en producciÃ³n**:

- **Costo de falsos negativos**: Un fraude no detectado puede costar mÃ¡s que revisar falsos positivos
- **Threshold ajustable**: Se puede ajustar el umbral de decisiÃ³n segÃºn el costo del negocio
- **Monitoreo continuo**: Los patrones de fraude evolucionan, requiere reentrenamiento periÃ³dico

### ğŸŒ¡ï¸ PredicciÃ³n de Temperatura con LSTM

#### Red Neuronal LSTM (3 capas)

| MÃ©trica       | Valor | DescripciÃ³n                                          |
| ------------- | ----- | ---------------------------------------------------- |
| **MAE**       | ~1.2Â°C| Error Absoluto Medio en predicciones                 |
| **RMSE**      | ~1.5Â°C| RaÃ­z del Error CuadrÃ¡tico Medio                      |
| **RÂ² Score**  | 0.92  | Explica el 92% de la varianza en los datos           |

**CaracterÃ­sticas del modelo**:

- ğŸ§  3 capas LSTM con 50 unidades cada una
- ğŸ“Š Entrada: 60 dÃ­as histÃ³ricos
- ğŸ¯ PredicciÃ³n: Temperatura mÃ­nima del siguiente dÃ­a
- â±ï¸ Dropout para regularizaciÃ³n y evitar overfitting
- ğŸ”„ Optimizador: Adam con early stopping

**ComparaciÃ³n LSTM vs Modelo ClÃ¡sico (Baseline)**:

- **LSTM**: MAE ~1.2Â°C, captura patrones estacionales complejos
- **Modelo ClÃ¡sico**: MAE ~2.1Â°C, Ãºtil como baseline
- **Mejora**: LSTM ~43% mejor en precisiÃ³n
- **Tiempo predicciÃ³n**: LSTM <100ms por predicciÃ³n

**Ventajas del enfoque LSTM**:

- âœ… Captura patrones temporales a largo plazo
- âœ… Maneja variaciones estacionales automÃ¡ticamente
- âœ… Generaliza bien a nuevos perÃ­odos
- âœ… Predicciones consistentes en diferentes Ã©pocas del aÃ±o

## ğŸ“ˆ Visualizaciones y AnÃ¡lisis

### Predictor de Casas

1. **AnÃ¡lisis de CaracterÃ­sticas** (`feature_analysis.png`)

   - DistribuciÃ³n de variables independientes
   - Correlaciones entre features y precio
   - DetecciÃ³n de outliers

2. **Predicciones del Modelo**
   - `predictions_vs_actual.png`: ComparaciÃ³n predicciones vs reales
   - `kaggle_predictions.png`: Resultados modelo Kaggle lineal
   - `kaggle_rf_predictions.png`: Resultados Random Forest Kaggle
   - LÃ­nea de regresiÃ³n ideal y distribuciÃ³n de errores

### Predictor de Titanic

1. **AnÃ¡lisis Exploratorio** (generado por `visualization.py`)

   - DistribuciÃ³n de supervivencia por clase, sexo, edad
   - AnÃ¡lisis de tarifas pagadas
   - Impacto del puerto de embarque
   - VisualizaciÃ³n de valores faltantes

2. **Feature Engineering**

   - CreaciÃ³n de `family_size` y `is_alone`
   - One-hot encoding de variables categÃ³ricas
   - ImputaciÃ³n inteligente de edad (mediana por clase/sexo)

3. **EvaluaciÃ³n del Modelo**
   - Matriz de confusiÃ³n detallada
   - Reporte de clasificaciÃ³n completo
   - AnÃ¡lisis de importancia de features

### DetecciÃ³n de Fraude

1. **AnÃ¡lisis Exploratorio de Datos** (EDA)

   - **DistribuciÃ³n de clases**: VisualizaciÃ³n del desbalance
   - **DistribuciÃ³n de montos**: ComparaciÃ³n fraude vs legÃ­timas
   - **AnÃ¡lisis temporal**: Patrones de fraude en el tiempo
   - **Correlaciones**: Heatmap de features V1-V28
   - **Boxplots**: DetecciÃ³n de outliers por clase

2. **Preprocesamiento y Balanceo**

   - VisualizaciÃ³n del efecto de SMOTE
   - ComparaciÃ³n distribuciones antes/despuÃ©s de balanceo
   - AnÃ¡lisis de splits (train/validation/test)

3. **EvaluaciÃ³n del Modelo**

   - **Matriz de confusiÃ³n**: Predicciones en conjunto de test
   - **Curva ROC**: AUC = 0.95
   - **Curva Precision-Recall**: Especialmente importante en datos desbalanceados
   - **Feature Importance**: Features mÃ¡s relevantes para detecciÃ³n
   - **DistribuciÃ³n de probabilidades**: SeparaciÃ³n entre clases

4. **Dashboard Interactivo** (Streamlit)
   - MÃ©tricas clave en tiempo real
   - Visualizaciones interactivas de rendimiento
   - AnÃ¡lisis de predicciones individuales
   - Explorador de datos con filtros
   - Analytics avanzado con insights del modelo

### PredicciÃ³n de Temperatura

1. **AnÃ¡lisis de Series Temporales**
   - VisualizaciÃ³n de temperaturas histÃ³ricas (10 aÃ±os)
   - IdentificaciÃ³n de patrones estacionales
   - AnÃ¡lisis de tendencias anuales

2. **Entrenamiento del Modelo LSTM**
   - Curva de pÃ©rdida de entrenamiento y validaciÃ³n
   - Convergencia del modelo a lo largo de Ã©pocas
   - DetecciÃ³n de overfitting/underfitting

3. **Predicciones vs Valores Reales**
   - GrÃ¡fico temporal de predicciones LSTM vs observaciones
   - AnÃ¡lisis de residuos (errores)
   - Diagrama de dispersiÃ³n (predicho vs real)

4. **ComparaciÃ³n de Modelos**
   - GrÃ¡fico comparativo LSTM vs modelo clÃ¡sico
   - Tabla de mÃ©tricas (MAE, RMSE, RÂ²)
   - AnÃ¡lisis de desempeÃ±o por estaciÃ³n del aÃ±o

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Core ML Stack

- **Python 3.8+**: Lenguaje de programaciÃ³n principal
- **pandas**: ManipulaciÃ³n y anÃ¡lisis de datos
- **numpy**: ComputaciÃ³n numÃ©rica y Ã¡lgebra lineal
- **scikit-learn**: Algoritmos de machine learning (regresiÃ³n, clasificaciÃ³n, RF)
- **matplotlib**: VisualizaciÃ³n de datos y grÃ¡ficos
- **seaborn**: Visualizaciones estadÃ­sticas avanzadas

### Deep Learning Stack

- **TensorFlow/Keras**: Redes neuronales LSTM para series temporales
- **Keras API**: ConstrucciÃ³n modular de redes neuronales

### Versiones EspecÃ­ficas

#### predictor-house

- `pandas==2.3.2`
- `numpy==2.3.3`
- `scikit-learn==1.7.2`
- `matplotlib==3.10.6`
- `jupyter==1.1.1`
- `streamlit==1.40.1`

#### predictor-titanic

- Versiones libres de pandas, numpy, matplotlib, seaborn, scikit-learn

#### fraude-detection

- `pandas`, `numpy`, `scikit-learn`
- `imbalanced-learn`: Para tÃ©cnicas de balanceo (SMOTE)
- `matplotlib`, `seaborn`, `plotly`: Visualizaciones
- `streamlit`: AplicaciÃ³n web multipÃ¡gina
- `jupyter`: Notebooks interactivos

#### prediction-temperature

- `pandas`, `numpy`: ManipulaciÃ³n de datos temporales
- `scikit-learn`: MinMaxScaler para normalizaciÃ³n
- `tensorflow >= 2.12.0`: Framework de deep learning
- `keras`: API para construcciÃ³n de LSTM
- `matplotlib`: Visualizaciones de series temporales
- `jupyter`: Notebooks para anÃ¡lisis

### Herramientas de Desarrollo

- **pickle/joblib**: SerializaciÃ³n de modelos entrenados
- **Jupyter Notebooks**: ExploraciÃ³n interactiva de datos
- **Streamlit**: Aplicaciones web interactivas
- **Git/GitHub**: Control de versiones y colaboraciÃ³n
- **imbalanced-learn**: Balanceo de clases desbalanceadas

## ğŸ“ Conceptos de Machine Learning Aplicados

### TÃ©cnicas Implementadas

- **RegresiÃ³n Lineal MÃºltiple**: PredicciÃ³n de valores continuos (precios de casas)
- **Random Forest**:
  - Ensemble learning para clasificaciÃ³n binaria (Titanic, Fraude)
  - Mejora de regresiÃ³n lineal en datos Kaggle (House Prices)
  - Robusto ante datos desbalanceados y outliers
- **Feature Engineering**:
  - CreaciÃ³n de variables derivadas (family_size, is_alone)
  - AnÃ¡lisis de importancia de features
- **Data Preprocessing**:
  - Manejo de valores faltantes (mediana, moda, estrategias inteligentes)
  - Encoding de variables categÃ³ricas (LabelEncoder, One-Hot)
  - Feature scaling y normalizaciÃ³n
  - **TÃ©cnicas de balanceo**: SMOTE para datos altamente desbalanceados
- **Redes Neuronales Recurrentes (LSTM)**:
  - Captura de dependencias temporales a largo plazo
  - Manejo de datos de series temporales
  - Arquitectura multi-capa para modelos complejos
  - RegularizaciÃ³n con Dropout
  - Early stopping para evitar overfitting
- **Train/Test/Validation Split**: DivisiÃ³n estratificada de datos
- **Model Persistence**: SerializaciÃ³n con pickle/joblib/Keras
- **MÃ©tricas de EvaluaciÃ³n**:
  - RegresiÃ³n: RÂ², MAE, RMSE
  - ClasificaciÃ³n: Accuracy, Precision, Recall, F1-Score, AUC-ROC
  - Confusion Matrix y Classification Report
  - Series Temporales: MAE, RMSE, RÂ² Score

### DesafÃ­os Resueltos

#### ğŸ  Predictor de Casas

- **Multicolinealidad**: AnÃ¡lisis de correlaciones entre features
- **Overfitting**: ValidaciÃ³n con train/test split
- **Escalabilidad**: Tres versiones (simple, Kaggle lineal, Kaggle RF)

#### ğŸš¢ Predictor de Titanic

- **Datos faltantes**: ImputaciÃ³n inteligente por grupos
- **Features categÃ³ricas**: Encoding apropiado
- **Feature engineering**: CreaciÃ³n de variables significativas
- **Interpretabilidad**: AnÃ¡lisis de feature importance

#### ğŸ’³ DetecciÃ³n de Fraude

- **Datos altamente desbalanceados**: 99.83% vs 0.17%
  - SoluciÃ³n: SMOTE para generar muestras sintÃ©ticas de la clase minoritaria
- **Alta dimensionalidad**: 30 features (28 de PCA)
  - SoluciÃ³n: Random Forest maneja bien alta dimensionalidad
- **Costo asimÃ©trico de errores**:
  - Falso negativo (fraude no detectado) es mÃ¡s costoso que falso positivo
  - SoluciÃ³n: OptimizaciÃ³n de threshold y mÃ©tricas enfocadas en recall
- **GeneralizaciÃ³n**:
  - ValidaciÃ³n en conjunto sin balancear para simular producciÃ³n
  - Monitoreo de mÃ©tricas en datos reales
- **Interpretabilidad**:
  - Feature importance para entender patrones de fraude
  - Visualizaciones de distribuciones por clase

#### ğŸŒ¡ï¸ PredicciÃ³n de Temperatura

- **Dependencias temporales a largo plazo**: LSTM captura relaciones entre temperaturas lejanas
- **Estacionalidad compleja**: Variaciones anuales y patrones no lineales
  - SoluciÃ³n: Redes LSTM de 3 capas con Dropout
- **NormalizaciÃ³n apropiada**: Datos en rango [0,1] para convergencia Ã³ptima
  - SoluciÃ³n: MinMaxScaler antes del entrenamiento
- **Overfitting en series temporales**: Modelos entrenados en un perÃ­odo pueden no generalizar
  - SoluciÃ³n: Early stopping, Dropout, validaciÃ³n temporal
- **SecuenciaciÃ³n de datos**: EstructuraciÃ³n de datos para entrada LSTM
  - SoluciÃ³n: Ventanas deslizantes de 60 dÃ­as como histÃ³rico
- **ComparaciÃ³n con baseline**: ValidaciÃ³n de que el modelo LSTM es realmente mejor
  - SoluciÃ³n: Modelo clÃ¡sico como punto de referencia

### Buenas PrÃ¡cticas Aplicadas

âœ… **Arquitectura Modular**: SeparaciÃ³n clara de responsabilidades (carga, preprocesamiento, modelo, visualizaciÃ³n)  
âœ… **ConfiguraciÃ³n Centralizada**: `config.py` con rutas absolutas y parÃ¡metros  
âœ… **Reproducibilidad**: `random_state` fijo para splits y modelos  
âœ… **Pandas 3.0 Ready**: Evita chained assignment con `inplace=True`  
âœ… **Logging Descriptivo**: Prints formateados con emojis y separadores  
âœ… **Persistencia de Modelos**: Guardado/carga con pickle/joblib para reutilizaciÃ³n  
âœ… **DocumentaciÃ³n**: READMEs detallados e instrucciones para agentes IA  
âœ… **ValidaciÃ³n Realista**: En fraude-detection, validaciÃ³n en datos sin balancear  
âœ… **MÃºltiples Notebooks**: SeparaciÃ³n de anÃ¡lisis, preprocesamiento, entrenamiento y evaluaciÃ³n

## ğŸ‘¨â€ğŸ’» Autor y PropÃ³sito

**Deep Learning Repository** - ColecciÃ³n educativa de proyectos de Machine Learning

Este repositorio fue creado con fines educativos para demostrar:

- ImplementaciÃ³n end-to-end de proyectos de ML (regresiÃ³n, clasificaciÃ³n, detecciÃ³n de anomalÃ­as)
- Arquitectura modular y escalable
- Buenas prÃ¡cticas de desarrollo en Data Science
- Manejo de diferentes tipos de problemas:
  - **RegresiÃ³n**: PredicciÃ³n de valores continuos
  - **ClasificaciÃ³n balanceada**: Datos con distribuciÃ³n similar entre clases
  - **ClasificaciÃ³n desbalanceada**: DetecciÃ³n de eventos raros con tÃ©cnicas de balanceo
- Pipeline completo desde datos crudos hasta aplicaciones web interactivas
- AplicaciÃ³n de tÃ©cnicas avanzadas (SMOTE, feature engineering, hyperparameter tuning)

### ğŸ“š Recursos Educativos

- **Kaggle Competitions**:
  - [House Prices - Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
  - [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- **Datasets pÃºblicos**:
  - Titanic incluido en Seaborn (`sns.load_dataset('titanic')`)
- **Instrucciones IA**: `.github/copilot-instructions.md` para agentes de desarrollo

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia **MIT**. Ver el archivo [`LICENSE`](LICENSE) para mÃ¡s detalles.

---

## ğŸ—‚ï¸ Ãndice de NavegaciÃ³n

- [ğŸš€ GuÃ­a RÃ¡pida](#-guÃ­a-rÃ¡pida) - Para principiantes y usuarios rÃ¡pidos
- [ğŸ¯ Proyectos Incluidos](#-proyectos-incluidos) - Detalles de cada proyecto
- [ğŸ“Š ComparaciÃ³n de Proyectos](#-comparaciÃ³n-de-proyectos) - Tabla comparativa
- [ğŸ“ Estructura del Repositorio](#-estructura-del-repositorio) - OrganizaciÃ³n de archivos
- [ğŸš€ InstalaciÃ³n y Uso](#-instalaciÃ³n-y-uso) - Pasos para ejecutar
- [ğŸ“Š Ejemplos de Uso](#-ejemplos-de-uso) - CÃ³digo prÃ¡ctico
- [ğŸ“‹ Datasets Utilizados](#-datasets-utilizados) - InformaciÃ³n de datos
- [ğŸ”¬ Rendimiento de los Modelos](#-rendimiento-de-los-modelos) - MÃ©tricas y resultados
- [ğŸ“ˆ Visualizaciones y AnÃ¡lisis](#-visualizaciones-y-anÃ¡lisis) - GrÃ¡ficos y dashboards
- [ğŸ› ï¸ TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas) - Stack tÃ©cnico
- [ğŸ“ Conceptos de Machine Learning](#-conceptos-de-machine-learning-aplicados) - TÃ©cnicas implementadas
- [ğŸ‘¨â€ğŸ’» Autor y PropÃ³sito](#-autor-y-propÃ³sito) - Contexto educativo
- [ğŸ“ PrÃ³ximas Mejoras](#-prÃ³ximas-mejoras) - Roadmap del proyecto

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas y muy valoradas. Para contribuir:

### ğŸ“‹ Pasos para Contribuir

1. **Fork del repositorio**

   ```bash
   git clone https://github.com/tu-usuario/repos-deep-learning.git
   cd repos-deep-learning
   ```

2. **Crear rama para tu feature**

   ```bash
   git checkout -b feature/nueva-caracteristica
   ```

3. **Realizar cambios y commit**

   ```bash
   git add .
   git commit -m 'AÃ±adir: [descripciÃ³n concisa del cambio]'
   ```

4. **Push y Pull Request**
   ```bash
   git push origin feature/nueva-caracteristica
   ```
   Luego crea un Pull Request en GitHub.

### ğŸ“ GuÃ­as de ContribuciÃ³n

#### CÃ³digo y Estructura

- âœ… **Mantener arquitectura modular**: No mezclar responsabilidades
- âœ… **Seguir convenciones de nombres**: `snake_case` para archivos y funciones
- âœ… **Usar rutas absolutas**: Siempre `config.py` para paths
- âœ… **Pandas 3.0 ready**: Evitar `df['col'].fillna(value, inplace=True)`
- âœ… **Documentar funciones**: AÃ±adir docstrings y prints descriptivos

#### DocumentaciÃ³n

- âœ… **Actualizar README**: Si aÃ±ades features o mejoras significativas
- âœ… **Mantener sincronÃ­a**: Los badges y versiones deben ser consistentes
- âœ… **Ejemplos prÃ¡cticos**: Incluir cÃ³digo de uso en READMEs

#### Calidad

- âœ… **Pruebas**: AÃ±adir tests unitarios para nuevas funcionalidades
- âœ… **Reproducibilidad**: Usar `random_state=42` para splits y modelos
- âœ… **Versionado**: Actualizar `requirements.txt` si se aÃ±aden dependencias

### ğŸ¨ Estilo del CÃ³digo

- **Black**: Formato automÃ¡tico de cÃ³digo
- **Type hints**: Usar anotaciones de tipo cuando sea posible
- **Comentarios**: Explicar el "porquÃ©" no solo el "quÃ©"
- **Logs**: Usar prints formateados con emojis para claridad

### ğŸ† Tipos de Contribuciones Bienvenidas

#### ğŸ“š DocumentaciÃ³n

- Mejora de READMEs
- AÃ±adir ejemplos de uso
- TraducciÃ³n a otros idiomas
- GuÃ­as de aprendizaje

#### ğŸ› Bug Fixes

- CorrecciÃ³n de errores en pipelines
- Mejora de preprocesamiento
- OptimizaciÃ³n de rendimiento

#### âœ¨ Nuevas Features

- Nuevos algoritmos de ML
- Visualizaciones avanzadas
- APIs para aplicaciones
- Nuevos datasets

#### ğŸ“Š AnÃ¡lisis y Experimentos

- ComparaciÃ³n de modelos
- AnÃ¡lisis de feature importance
- MÃ©tricas de rendimiento mejoradas
- Estudios de casos

### ğŸ“ Â¿Necesitas ayuda?

- Abre un [issue](https://github.com/devlitus/repos-deep-learning/issues) para preguntas
- Revisa las [instrucciones para agentes IA](.github/copilot-instructions.md)
- Explora los [notebooks existentes](fraude-detection/notebooks/) como referencia

---

**Â¿Tienes preguntas?** Abre un [issue](https://github.com/devlitus/repos-deep-learning/issues) en el repositorio.

---

<div align="center">

Hecho con â¤ï¸ para la comunidad de Data Science

[![Star on GitHub](https://img.shields.io/github/stars/devlitus/repos-deep-learning?style=social)](https://github.com/devlitus/repos-deep-learning)

</div>

## ğŸ“ PrÃ³ximas Mejoras

### Predictor de Casas

- [ ] ValidaciÃ³n cruzada (k-fold CV)
- [ ] Hyperparameter tuning (GridSearchCV)
- [ ] MÃ¡s algoritmos (XGBoost, Gradient Boosting)
- [ ] API REST con FastAPI
- [ ] Dashboard avanzado con Plotly/Dash
- [ ] Feature importance analysis
- [ ] DetecciÃ³n automÃ¡tica de outliers

### Predictor de Titanic

- [ ] ComparaciÃ³n con otros clasificadores (SVM, Gradient Boosting)
- [ ] OptimizaciÃ³n de hiperparÃ¡metros Random Forest
- [ ] Feature engineering avanzado (tÃ­tulos en nombres, cabinas)
- [ ] AnÃ¡lisis de SHAP values
- [ ] Cross-validation para robustez
- [ ] Deployment como servicio web

### DetecciÃ³n de Fraude

- [x] Pipeline completo de preprocesamiento
- [x] ImplementaciÃ³n de SMOTE para balanceo
- [x] AplicaciÃ³n web Streamlit multipÃ¡gina
- [x] 4 notebooks Jupyter documentados
- [x] Persistencia de datos procesados
- [ ] ComparaciÃ³n con otros modelos (XGBoost, LightGBM, Neural Networks)
- [ ] Hyperparameter tuning con RandomizedSearchCV
- [ ] AnÃ¡lisis de SHAP values para interpretabilidad
- [ ] DetecciÃ³n de concept drift y reentrenamiento automÃ¡tico
- [ ] API REST para integraciÃ³n en sistemas de producciÃ³n
- [ ] Sistema de alertas en tiempo real
- [ ] AnÃ¡lisis de series temporales de fraude
- [ ] Feature engineering avanzado sobre features PCA
- [ ] Ensemble methods (stacking, voting)
- [ ] Monitoreo de performance en producciÃ³n

### PredicciÃ³n de Temperatura

- [x] Pipeline completo de carga y preprocesamiento
- [x] Modelo LSTM de 3 capas entrenado
- [x] Modelo clÃ¡sico (baseline) para comparaciÃ³n
- [x] Visualizaciones de predicciones vs reales
- [x] MÃ©tricas de evaluaciÃ³n (MAE, RMSE, RÂ²)
- [ ] PredicciÃ³n multivariable (incluir other weather variables)
- [ ] Attention mechanism para mejorar LSTM
- [ ] Ensemble de mÃºltiples modelos LSTM
- [ ] PredicciÃ³n de intervalos de confianza
- [ ] AnÃ¡lisis de errores por estaciÃ³n del aÃ±o
- [ ] AplicaciÃ³n web Streamlit para predicciones interactivas
- [ ] Hyperparameter tuning automÃ¡tico (Bayesian Optimization)
- [ ] ValidaciÃ³n cruzada temporal
- [ ] Detectar cambios de clima (concept drift)
- [ ] API REST para servir predicciones

### General

- [ ] Tests unitarios completos (pytest)
- [ ] CI/CD pipeline con GitHub Actions
- [ ] DockerizaciÃ³n de los cuatro proyectos
- [ ] Notebooks Jupyter documentados (completo en fraude-detection y prediction-temperature)
- [ ] Logging avanzado con `logging` module
- [ ] DocumentaciÃ³n con MkDocs o Sphinx
- [ ] IntegraciÃ³n con MLflow para tracking de experimentos
- [ ] ComparaciÃ³n de arquitecturas de redes neuronales (RNN, GRU, Transformer)
