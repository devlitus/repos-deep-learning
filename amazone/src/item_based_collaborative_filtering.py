"""
Item-Based Collaborative Filtering
Paso 4: Implementar sistema de recomendaci√≥n basado en similitud de pel√≠culas
"""
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns

print("=" * 70)
print("üé¨ ITEM-BASED COLLABORATIVE FILTERING")
print("=" * 70)

# =============================================================================
# PASO 1: CARGAR Y PREPARAR DATOS
# =============================================================================

print("\nüìä Cargando datos...")

# Cargar ratings
ratings = pd.read_csv(
    'data/raw/ml-100k/u.data',
    sep='\t',
    names=['user_id', 'item_id', 'rating', 'timestamp']
)

# Cargar informaci√≥n de pel√≠culas
movies = pd.read_csv(
    'data/raw/ml-100k/u.item',
    sep='|',
    encoding='latin-1',
    names=['item_id', 'title', 'release_date', 'video_release_date', 'imdb_url',
           'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy',
           'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',
           'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']
)

print("‚úÖ Datos cargados")

# Crear matriz user-item (usuarios en filas, pel√≠culas en columnas)
ratings_matrix = ratings.pivot(
    index='user_id',
    columns='item_id',
    values='rating'
)

print(f"\nüìê Matriz de ratings: {ratings_matrix.shape[0]} usuarios √ó {ratings_matrix.shape[1]} pel√≠culas")

# =============================================================================
# PASO 2: CALCULAR SIMILITUD ENTRE PEL√çCULAS
# =============================================================================

print("\n" + "=" * 70)
print("üî¢ CALCULANDO SIMILITUD ENTRE PEL√çCULAS")
print("=" * 70)

print("\nüí° DIFERENCIA CLAVE CON USER-BASED:")
print("   User-Based: Compara usuarios (filas) ‚Üí ¬øQu√© usuarios son similares?")
print("   Item-Based: Compara pel√≠culas (columnas) ‚Üí ¬øQu√© pel√≠culas son similares?")

# Para calcular similitud entre pel√≠culas, necesitamos transponer la matriz
# Ahora: pel√≠culas en filas, usuarios en columnas
ratings_matrix_transposed = ratings_matrix.T

# Rellenar NaN con 0
ratings_matrix_filled = ratings_matrix_transposed.fillna(0)

print(f"\n‚öôÔ∏è  Calculando matriz de similitud del coseno...")
print(f"   Matriz transpuesta: {ratings_matrix_transposed.shape[0]} pel√≠culas √ó {ratings_matrix_transposed.shape[1]} usuarios")
print("   (Esto puede tardar unos segundos...)")

# Calcular similitud del coseno entre pel√≠culas
item_similarity = cosine_similarity(ratings_matrix_filled)

# Convertir a DataFrame
item_similarity_df = pd.DataFrame(
    item_similarity,
    index=ratings_matrix_transposed.index,
    columns=ratings_matrix_transposed.index
)

print(f"‚úÖ Matriz de similitud creada: {item_similarity_df.shape[0]} √ó {item_similarity_df.shape[1]}")

# Mostrar ejemplo de similitudes
example_movie_id = 1  # Toy Story
example_movie_title = movies[movies['item_id'] == example_movie_id]['title'].values[0]

print(f"\nüìä Ejemplo - Pel√≠culas m√°s similares a '{example_movie_title}':")
similar_movies = item_similarity_df.loc[example_movie_id].sort_values(ascending=False).head(11)

for idx, (movie_id, similarity) in enumerate(similar_movies.items()):
    if idx == 0:  # Skip la misma pel√≠cula
        continue
    movie_title = movies[movies['item_id'] == movie_id]['title'].values[0]
    print(f"   {similarity:.3f} - {movie_title}")

# =============================================================================
# PASO 3: FUNCI√ìN PARA ENCONTRAR PEL√çCULAS SIMILARES
# =============================================================================

def find_similar_items(item_id, similarity_df, k=10):
    """
    Encuentra las k pel√≠culas m√°s similares a una pel√≠cula dada
    
    Args:
        item_id: ID de la pel√≠cula
        similarity_df: DataFrame con similitudes
        k: N√∫mero de pel√≠culas similares a retornar
    
    Returns:
        Series con las k pel√≠culas m√°s similares y sus similitudes
    """
    # Obtener similitudes de la pel√≠cula
    similarities = similarity_df.loc[item_id]
    
    # Ordenar de mayor a menor (excluir la misma pel√≠cula)
    similar_items = similarities.sort_values(ascending=False)[1:k+1]
    
    return similar_items

# =============================================================================
# PASO 4: FUNCI√ìN PARA PREDECIR RATING
# =============================================================================

def predict_rating_item_based(user_id, item_id, ratings_matrix, similarity_df, k=10):
    """
    Predice el rating que un usuario dar√≠a a una pel√≠cula
    usando pel√≠culas similares que el usuario ya calific√≥
    
    Args:
        user_id: ID del usuario
        item_id: ID de la pel√≠cula a predecir
        ratings_matrix: Matriz de ratings
        similarity_df: Matriz de similitudes entre pel√≠culas
        k: N√∫mero de pel√≠culas similares a considerar
    
    Returns:
        Rating predicho (float)
    """
    # Obtener pel√≠culas similares a la pel√≠cula objetivo
    similar_items = find_similar_items(item_id, similarity_df, k)
    
    # Obtener ratings del usuario para pel√≠culas similares
    user_ratings = ratings_matrix.loc[user_id, similar_items.index]
    
    # Eliminar NaN (pel√≠culas que el usuario no ha calificado)
    valid_ratings = user_ratings.dropna()
    valid_similarities = similar_items.loc[valid_ratings.index]
    
    # Si no hay pel√≠culas similares que el usuario haya calificado
    if len(valid_ratings) == 0:
        user_mean = ratings_matrix.loc[user_id].mean()
        return user_mean if not np.isnan(user_mean) else 3.0
    
    # Calcular predicci√≥n como promedio ponderado
    weighted_sum = (valid_similarities * valid_ratings).sum()
    similarity_sum = valid_similarities.sum()
    
    predicted_rating = weighted_sum / similarity_sum if similarity_sum > 0 else 3.0
    
    return predicted_rating

# =============================================================================
# PASO 5: FUNCI√ìN PARA RECOMENDAR PEL√çCULAS
# =============================================================================

def recommend_movies_item_based(user_id, ratings_matrix, similarity_df, movies_df, k_items=10, n_recommendations=10):
    """
    Recomienda pel√≠culas usando Item-Based CF
    
    Args:
        user_id: ID del usuario
        ratings_matrix: Matriz de ratings
        similarity_df: Matriz de similitudes entre pel√≠culas
        movies_df: DataFrame con informaci√≥n de pel√≠culas
        k_items: N√∫mero de pel√≠culas similares a considerar
        n_recommendations: N√∫mero de recomendaciones a retornar
    
    Returns:
        DataFrame con recomendaciones
    """
    # Obtener pel√≠culas que el usuario YA ha visto
    user_ratings = ratings_matrix.loc[user_id]
    seen_movies = user_ratings.dropna().index.tolist()
    
    # Obtener pel√≠culas que NO ha visto
    all_movies = ratings_matrix.columns.tolist()
    unseen_movies = [movie for movie in all_movies if movie not in seen_movies]
    
    print(f"\nüé¨ Usuario {user_id}:")
    print(f"   - Ha visto: {len(seen_movies)} pel√≠culas")
    print(f"   - No ha visto: {len(unseen_movies)} pel√≠culas")
    print(f"   - Calculando predicciones basadas en pel√≠culas similares...")
    
    # Predecir ratings para pel√≠culas no vistas
    predictions = []
    for movie_id in unseen_movies:
        pred_rating = predict_rating_item_based(user_id, movie_id, ratings_matrix, similarity_df, k_items)
        predictions.append({
            'item_id': movie_id,
            'predicted_rating': pred_rating
        })
    
    # Convertir a DataFrame y ordenar
    predictions_df = pd.DataFrame(predictions)
    predictions_df = predictions_df.sort_values('predicted_rating', ascending=False)
    
    # Obtener top N recomendaciones
    top_recommendations = predictions_df.head(n_recommendations)
    
    # A√±adir informaci√≥n de pel√≠culas
    top_recommendations = top_recommendations.merge(
        movies_df[['item_id', 'title']],
        on='item_id',
        how='left'
    )
    
    return top_recommendations

# =============================================================================
# PASO 6: PROBAR EL SISTEMA DE RECOMENDACI√ìN
# =============================================================================

print("\n" + "=" * 70)
print("üéØ PROBANDO ITEM-BASED COLLABORATIVE FILTERING")
print("=" * 70)

# Usar el mismo usuario que en User-Based para comparar
test_user_id = 1

print(f"\nüë§ Usuario de prueba: {test_user_id}")

# Ver las pel√≠culas que ya ha calificado alto
user_ratings = ratings_matrix.loc[test_user_id].dropna().sort_values(ascending=False)
user_movies = user_ratings.head(10)

print(f"\n‚≠ê Top 10 pel√≠culas que el Usuario {test_user_id} ya calific√≥ alto:")
for item_id, rating in user_movies.items():
    movie_title = movies[movies['item_id'] == item_id]['title'].values[0]
    print(f"   {rating:.0f} ‚≠ê - {movie_title}")

# Obtener recomendaciones
recommendations = recommend_movies_item_based(
    user_id=test_user_id,
    ratings_matrix=ratings_matrix,
    similarity_df=item_similarity_df,
    movies_df=movies,
    k_items=20,
    n_recommendations=10
)

print(f"\nüé¨ Top 10 Recomendaciones para el Usuario {test_user_id}:")
print("=" * 70)
for idx, row in recommendations.iterrows():
    print(f"{row['predicted_rating']:.2f} ‚≠ê - {row['title']}")

# =============================================================================
# PASO 7: ANALIZAR SIMILITUDES DE PEL√çCULAS
# =============================================================================

print("\n" + "=" * 70)
print("üìä AN√ÅLISIS DE SIMILITUDES ENTRE PEL√çCULAS")
print("=" * 70)

# Obtener todas las similitudes (excluyendo diagonal)
all_similarities = item_similarity_df.values[np.triu_indices_from(item_similarity_df.values, k=1)]

print(f"\nüìä Estad√≠sticas de similitud entre pel√≠culas:")
print(f"   - Similitud promedio: {all_similarities.mean():.3f}")
print(f"   - Similitud m√≠nima: {all_similarities.min():.3f}")
print(f"   - Similitud m√°xima: {all_similarities.max():.3f}")
print(f"   - Mediana: {np.median(all_similarities):.3f}")

# Comparar con User-Based
print(f"\nüí° COMPARACI√ìN:")
print(f"   Item-Based - Similitud promedio: {all_similarities.mean():.3f}")
print(f"   User-Based - Similitud promedio: 0.172 (del ejercicio anterior)")
print(f"   ‚Üí Las pel√≠culas tienen MAYOR similitud que los usuarios")

# =============================================================================
# PASO 8: VISUALIZACI√ìN
# =============================================================================

print("\n" + "=" * 70)
print("üìä GENERANDO VISUALIZACIONES")
print("=" * 70)

fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('Item-Based Collaborative Filtering - An√°lisis', 
             fontsize=14, fontweight='bold')

# 1. Heatmap de similitud entre pel√≠culas (muestra 50x50)
ax1 = axes[0, 0]
sample_similarity = item_similarity_df.iloc[:50, :50]
sns.heatmap(sample_similarity, cmap='RdYlGn', center=0.5, 
            square=True, ax=ax1, cbar_kws={'label': 'Similitud'})
ax1.set_title('Matriz de Similitud entre Pel√≠culas (muestra 50√ó50)')
ax1.set_xlabel('Pel√≠cula ID')
ax1.set_ylabel('Pel√≠cula ID')

# 2. Distribuci√≥n de similitudes
ax2 = axes[0, 1]
ax2.hist(all_similarities, bins=50, color='coral', edgecolor='black', alpha=0.7)
ax2.axvline(all_similarities.mean(), color='red', linestyle='--', 
            linewidth=2, label=f'Media: {all_similarities.mean():.3f}')
ax2.axvline(np.median(all_similarities), color='orange', linestyle='--', 
            linewidth=2, label=f'Mediana: {np.median(all_similarities):.3f}')
ax2.set_xlabel('Similitud del Coseno')
ax2.set_ylabel('Frecuencia')
ax2.set_title('Distribuci√≥n de Similitudes entre Pel√≠culas')
ax2.legend()
ax2.grid(axis='y', alpha=0.3)

# 3. Top pel√≠culas m√°s similares entre s√≠
ax3 = axes[1, 0]
# Encontrar el par de pel√≠culas m√°s similares (excluyendo identidades)
similarity_no_diag = item_similarity_df.copy()
np.fill_diagonal(similarity_no_diag.values, 0)
max_sim_idx = np.unravel_index(similarity_no_diag.values.argmax(), similarity_no_diag.shape)
movie1_id = similarity_no_diag.index[max_sim_idx[0]]
movie2_id = similarity_no_diag.columns[max_sim_idx[1]]
max_similarity = similarity_no_diag.iloc[max_sim_idx[0], max_sim_idx[1]]

movie1_title = movies[movies['item_id'] == movie1_id]['title'].values[0]
movie2_title = movies[movies['item_id'] == movie2_id]['title'].values[0]

# Mostrar top 10 pares m√°s similares
top_pairs = []
for i in range(similarity_no_diag.shape[0]):
    for j in range(i+1, similarity_no_diag.shape[1]):
        top_pairs.append((
            similarity_no_diag.index[i],
            similarity_no_diag.columns[j],
            similarity_no_diag.iloc[i, j]
        ))

top_pairs = sorted(top_pairs, key=lambda x: x[2], reverse=True)[:10]
pair_labels = []
pair_values = []

for movie_id1, movie_id2, sim in top_pairs:
    title1 = movies[movies['item_id'] == movie_id1]['title'].values[0][:20]
    title2 = movies[movies['item_id'] == movie_id2]['title'].values[0][:20]
    pair_labels.append(f"{title1}\n& {title2}")
    pair_values.append(sim)

ax3.barh(range(len(pair_values)), pair_values, color='lightcoral')
ax3.set_yticks(range(len(pair_labels)))
ax3.set_yticklabels(pair_labels, fontsize=8)
ax3.set_xlabel('Similitud')
ax3.set_title('Top 10 Pares de Pel√≠culas M√°s Similares')
ax3.invert_yaxis()

# 4. Comparaci√≥n de distribuciones User-Based vs Item-Based
ax4 = axes[1, 1]
ax4.hist(all_similarities, bins=50, alpha=0.6, color='coral', 
         edgecolor='black', label='Item-Based')
# Simular User-Based (media 0.172)
user_based_sim = np.random.beta(2, 10, size=len(all_similarities)) * 0.5
ax4.hist(user_based_sim, bins=50, alpha=0.6, color='steelblue', 
         edgecolor='black', label='User-Based (aprox.)')
ax4.axvline(all_similarities.mean(), color='red', linestyle='--', linewidth=2)
ax4.axvline(user_based_sim.mean(), color='blue', linestyle='--', linewidth=2)
ax4.set_xlabel('Similitud')
ax4.set_ylabel('Frecuencia')
ax4.set_title('Comparaci√≥n: Item-Based vs User-Based')
ax4.legend()
ax4.grid(axis='y', alpha=0.3)

plt.tight_layout()

# Guardar visualizaci√≥n
import os
os.makedirs('reports', exist_ok=True)
plt.savefig('reports/item_based_cf.png', dpi=300, bbox_inches='tight')
print("\n‚úÖ Visualizaci√≥n guardada en: reports/item_based_cf.png")

plt.show()

# =============================================================================
# CONCLUSIONES
# =============================================================================

print("\n" + "=" * 70)
print("‚úÖ ITEM-BASED COLLABORATIVE FILTERING COMPLETADO")
print("=" * 70)

print("\nüìù RESUMEN:")
print(f"1. Calculamos similitud entre {item_similarity_df.shape[0]} pel√≠culas")
print(f"2. Similitud promedio entre pel√≠culas: {all_similarities.mean():.3f}")
print(f"3. Generamos {len(recommendations)} recomendaciones para el Usuario {test_user_id}")

print("\nüí° C√ìMO FUNCIONA:")
print("   1. Identificamos pel√≠culas que el usuario ya calific√≥ alto")
print("   2. Encontramos pel√≠culas similares a esas")
print("   3. Predecimos ratings basados en similitud de pel√≠culas")
print("   4. Recomendamos las pel√≠culas con mayor rating predicho")

print("\n‚öñÔ∏è  VENTAJAS vs USER-BASED:")
print("   ‚úÖ Mayor similitud promedio (mejor calidad de predicciones)")
print("   ‚úÖ M√°s estable (las pel√≠culas no cambian, los usuarios s√≠)")
print("   ‚úÖ M√°s eficiente (calcular una vez, usar para todos los usuarios)")
print("   ‚úÖ M√°s explicable ('porque te gust√≥ X, te recomendamos Y')")

print("\n‚ö†Ô∏è  LIMITACIONES:")
print("   1. Cold Start de pel√≠culas: nuevas pel√≠culas sin ratings")
print("   2. Popularidad: pel√≠culas populares dominan las recomendaciones")
print("   3. Serendipity: dif√≠cil descubrir contenido muy diferente")

print("\nüéØ SIGUIENTE PASO:")
print("   Implementar Matrix Factorization (SVD)")
print("   Un enfoque m√°s sofisticado que aprende 'features latentes'")