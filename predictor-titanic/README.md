# ğŸš¢ Predictor de Supervivencia del Titanic

Proyecto educativo de Machine Learning para clasificar si un pasajero del Titanic sobreviviÃ³ o no. Este proyecto sigue el **patrÃ³n arquitectÃ³nico estÃ¡ndar** definido en `.github/copilot-instructions.md`.

**Ãšltima actualizaciÃ³n:** 7 de octubre de 2025

## ğŸ“‹ Resumen rÃ¡pido

- **Problema:** ClasificaciÃ³n binaria (target: `survived`)
- **Algoritmo:** Random Forest Classifier
- **Dataset:** `seaborn.load_dataset('titanic')` (891 pasajeros)
- **Accuracy:** 81.01%
- **Features principales:** Sexo (36%), Precio del ticket (21%), Edad (17%)

## ğŸ¯ Estructura del Proyecto

```
predictor-titanic/
â”œâ”€ main.py                  # ğŸš€ PUNTO DE ENTRADA - Pipeline completo
â”œâ”€ config.py                # âš™ï¸ ConfiguraciÃ³n centralizada
â”œâ”€ requirements.txt
â”œâ”€ data/
â”œâ”€ models/
â”‚  â””â”€ titanic_random_forest.pkl
â”œâ”€ src/
â”‚  â”œâ”€ data_loader.py        # Carga y exploraciÃ³n de datos
â”‚  â”œâ”€ data_preprocessing.py # Limpieza y feature engineering
â”‚  â”œâ”€ model.py              # Entrenamiento y evaluaciÃ³n
â”‚  â”œâ”€ predictor.py          # Predicciones con modelo guardado
â”‚  â”œâ”€ visualization.py      # GrÃ¡ficos exploratorios
â”‚  â””â”€ app.py                # App interactiva (Streamlit)
â””â”€ reports/
```

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### InstalaciÃ³n

```powershell
# Crear entorno virtual
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt
```

### Ejecutar Pipeline Completo

```powershell
cd predictor-titanic
python main.py
```

Este comando ejecuta todo el flujo:

1. âœ… Carga de datos
2. âœ… ExploraciÃ³n inicial
3. âœ… Preprocesamiento
4. âœ… Entrenamiento del modelo
5. âœ… EvaluaciÃ³n con mÃ©tricas
6. âœ… Guardado del modelo

### Hacer Predicciones

```powershell
python src/predictor.py
```

### Visualizaciones

```powershell
python src/visualization.py
```

### App Interactiva (Streamlit)

```powershell
streamlit run src/app.py
```

## ğŸ“Š Flujo de Trabajo EstÃ¡ndar

El proyecto sigue el patrÃ³n definido en las instrucciones:

```
load_data() â†’ explore_data() â†’ prepare_data() â†’
split_data() â†’ train_model() â†’ evaluate_model() â†’
save_model() â†’ predict()
```

Cada mÃ³dulo es **ejecutable independientemente** para testing:

```powershell
python src/data_loader.py        # Carga y explora datos
python src/data_preprocessing.py # Preprocesa y muestra resultados
python src/model.py              # Entrena y evalÃºa modelo
python src/predictor.py          # Hace predicciones de ejemplo
```

## ğŸ§¹ Preprocesamiento de Datos

Implementado en `data_preprocessing.py`:

1. **Manejo de valores faltantes:**

   - `age`: Rellenado con mediana (28 aÃ±os)
   - `embarked`: Rellenado con moda ('S' - Southampton)

2. **ConversiÃ³n de variables categÃ³ricas:**

   - `sex`: male â†’ 0, female â†’ 1
   - `embarked`: C â†’ 0, Q â†’ 1, S â†’ 2

3. **Feature Engineering:**

   - `family_size`: sibsp + parch + 1
   - `is_alone`: 1 si viaja solo, 0 si no

4. **Features finales (9 variables):**
   - `pclass`, `sex`, `age`, `sibsp`, `parch`
   - `fare`, `embarked`, `family_size`, `is_alone`

## ğŸ¯ Resultados del Modelo

### MÃ©tricas en Test Set

| MÃ©trica       | Valor  |
| ------------- | ------ |
| **Accuracy**  | 81.01% |
| **Precision** | 79.66% |
| **Recall**    | 68.12% |
| **F1-Score**  | 0.7344 |

### Importancia de Variables

| Feature         | Importancia |
| --------------- | ----------- |
| **sex**         | 35.9%       |
| **fare**        | 20.5%       |
| **age**         | 17.3%       |
| **pclass**      | 11.9%       |
| **family_size** | 4.7%        |

## âš™ï¸ ConfiguraciÃ³n

Todos los parÃ¡metros estÃ¡n centralizados en `config.py`:

```python
# HiperparÃ¡metros del modelo
MODEL_PARAMS = {
    'n_estimators': 100,
    'max_depth': 10,
    'min_samples_split': 5,
    'min_samples_leaf': 2,
    'random_state': 42
}

# DivisiÃ³n train/test
TEST_SIZE = 0.2
RANDOM_STATE = 42
```

## ğŸ“¦ Dependencias

- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- streamlit (para app interactiva)
- joblib (para serializaciÃ³n del modelo)

## ğŸ” Contexto HistÃ³rico

El RMS Titanic se hundiÃ³ el 15 de abril de 1912. De los 2,224 pasajeros y tripulaciÃ³n, solo sobrevivieron 710 personas (32%).

### Factores de supervivencia:

- **Mujeres:** 74% de supervivencia
- **Hombres:** 19% de supervivencia
- **1ra Clase:** 63% de supervivencia
- **3ra Clase:** 24% de supervivencia

## ğŸ“ Notas de ImplementaciÃ³n

- âœ… Rutas absolutas configuradas en `config.py`
- âœ… Sin chained assignment (compatible con pandas 3.0)
- âœ… Uso de `joblib` para persistencia del modelo
- âœ… Output formateado para claridad educativa
- âœ… Reproducibilidad garantizada con `random_state=42`

## ğŸ“ PropÃ³sito Educativo

Este proyecto demuestra:

- Pipeline completo de ML de principio a fin
- Preprocesamiento robusto de datos
- Feature engineering bÃ¡sico
- EvaluaciÃ³n exhaustiva con mÃºltiples mÃ©tricas
- Persistencia y reutilizaciÃ³n de modelos
- Arquitectura modular y mantenible

- Relleno de faltantes: `age` (mediana por `sex`+`pclass`), `embarked` (moda), `fare` (mediana).
- Feature engineering: `family_size = sibsp + parch + 1`; `is_alone`.
- CodificaciÃ³n: variables categÃ³ricas (`sex`, `embarked`) via dummies/one-hot.

Nota: evitar chained assignment con `inplace=True`; usar asignaciones directas para compatibilidad con pandas 2.x/3.x.

## Entrenamiento y persistencia

El entrenamiento usa RandomForestClassifier. MÃ©tricas calculadas: accuracy, precision, recall, f1 y matriz de confusiÃ³n.
El modelo se guarda con `pickle` en `models/titanic_random_forest.pkl`.

Ejemplo de guardado:

```python
import pickle
with open('models/titanic_random_forest.pkl', 'wb') as f:
    pickle.dump(modelo, f)
```

## Errores comunes y soluciones

- No module named 'sklearn' â†’ `pip install scikit-learn`
- No module named 'seaborn' â†’ `pip install seaborn`
- Errores de import desde `src/`: ejecutar desde la raÃ­z del proyecto o ajustar `PYTHONPATH`.

## Pendientes / mejoras sugeridas

- Completar `config.py` con rutas y parÃ¡metros (usar rutas absolutas basadas en `BASE_DIR`).
- AÃ±adir `main.py` que orqueste el pipeline completo.
- Agregar `predictor.py` para cargar modelo y predecir nuevos casos.
- Implementar tests unitarios en `test/`.

---
