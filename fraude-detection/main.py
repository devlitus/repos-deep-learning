"""
Pipeline Principal del Proyecto de Detecci√≥n de Fraude
Ejecuta todo el flujo de trabajo de principio a fin
"""
import sys
from pathlib import Path

# Agregar la ra√≠z del proyecto al PATH
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

import argparse
from src.data.load import load_data, explore_data
from src.data.preprocess import preprocess_pipeline
from src.visualization.plots import generate_all_plots
from src.models.train import (
    train_logistic_regression,
    train_random_forest,
    save_model,
    compare_models
)
from src.models.evaluate import (
    load_model,
    evaluate_on_test,
    plot_confusion_matrix,
    plot_roc_curve,
    plot_precision_recall_curve
)


def print_header(text):
    """Imprime un encabezado visual"""
    print("\n" + "="*70)
    print(f"  {text}")
    print("="*70)


def run_full_pipeline(skip_eda=False, skip_training=False, model_name="random_forest"):
    """
    Ejecuta el pipeline completo del proyecto
    
    Args:
        skip_eda (bool): Si True, omite el an√°lisis exploratorio
        skip_training (bool): Si True, omite el entrenamiento (usa modelos guardados)
        model_name (str): Nombre del modelo a evaluar
    """
    
    print_header("üöÄ PROYECTO: DETECCI√ìN DE FRAUDE CON TARJETAS DE CR√âDITO")
    
    # =========================================================================
    # PASO 1: CARGA DE DATOS
    # =========================================================================
    print_header("üìÇ PASO 1: CARGA DE DATOS")
    data = load_data()
    
    if data is None:
        print("‚ùå Error: No se pudo cargar el dataset. Abortando pipeline.")
        return
    
    explore_data(data)
    
    # =========================================================================
    # PASO 2: AN√ÅLISIS EXPLORATORIO (EDA)
    # =========================================================================
    if not skip_eda:
        print_header("üìä PASO 2: AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)")
        print("‚è≥ Generando visualizaciones (esto puede tardar 1-2 minutos)...")
        generate_all_plots(data)
        print("‚úÖ Visualizaciones generadas en reports/figures/")
    else:
        print_header("‚è≠Ô∏è PASO 2: EDA OMITIDO")
    
    # =========================================================================
    # PASO 3: PREPROCESAMIENTO
    # =========================================================================
    print_header("üîß PASO 3: PREPROCESAMIENTO DE DATOS")
    processed_data = preprocess_pipeline(data, apply_balancing=True)
    
    X_train = processed_data['X_train']
    y_train = processed_data['y_train']
    X_val = processed_data['X_val']
    y_val = processed_data['y_val']
    X_test = processed_data['X_test']
    y_test = processed_data['y_test']
    
    print("\n‚úÖ Datos preprocesados y listos para entrenamiento")
    
    # =========================================================================
    # PASO 4: ENTRENAMIENTO DE MODELOS
    # =========================================================================
    if not skip_training:
        print_header("ü§ñ PASO 4: ENTRENAMIENTO DE MODELOS")
        
        all_metrics = []
        
        # Entrenar Logistic Regression
        print("\n1Ô∏è‚É£ Entrenando Logistic Regression...")
        lr_model, lr_metrics = train_logistic_regression(X_train, y_train, X_val, y_val)
        save_model(lr_model, "logistic_regression")
        all_metrics.append(lr_metrics)
        
        # Entrenar Random Forest
        print("\n2Ô∏è‚É£ Entrenando Random Forest...")
        rf_model, rf_metrics = train_random_forest(X_train, y_train, X_val, y_val)
        save_model(rf_model, "random_forest")
        all_metrics.append(rf_metrics)
        
        # Comparar modelos
        compare_models(all_metrics)
        
        print("\n‚úÖ Modelos entrenados y guardados en models/")
    else:
        print_header("‚è≠Ô∏è PASO 4: ENTRENAMIENTO OMITIDO (usando modelos guardados)")
    
    # =========================================================================
    # PASO 5: EVALUACI√ìN FINAL EN TEST SET
    # =========================================================================
    print_header("üß™ PASO 5: EVALUACI√ìN FINAL EN TEST SET")
    
    try:
        # Cargar el mejor modelo
        print(f"\nüì¶ Cargando modelo: {model_name}")
        model = load_model(model_name)
        
        # Evaluar en test
        y_pred, y_pred_proba, cm = evaluate_on_test(model, X_test, y_test, model_name.replace('_', ' ').title())
        
        # Generar visualizaciones
        print("\nüé® Generando visualizaciones finales...")
        plot_confusion_matrix(cm, model_name.replace('_', ' ').title())
        plot_roc_curve(y_test, y_pred_proba, model_name.replace('_', ' ').title())
        plot_precision_recall_curve(y_test, y_pred_proba, model_name.replace('_', ' ').title())
        
        print("\n‚úÖ Evaluaci√≥n completada")
        
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ el modelo '{model_name}.pkl'")
        print("   Ejecuta el pipeline con '--train' para entrenar los modelos primero.")
        return
    
    # =========================================================================
    # RESUMEN FINAL
    # =========================================================================
    print_header("üìã RESUMEN DEL PROYECTO")
    
    print("\n‚úÖ Pipeline completado exitosamente!")
    print("\nüìÅ Archivos generados:")
    print("   ‚Ä¢ Visualizaciones EDA: reports/figures/")
    print("   ‚Ä¢ Modelos entrenados: models/")
    print("   ‚Ä¢ Gr√°ficos de evaluaci√≥n: reports/figures/")
    
    print("\nüéØ Pr√≥ximos pasos sugeridos:")
    print("   1. Revisar las visualizaciones en reports/figures/")
    print("   2. Analizar las m√©tricas del modelo")
    print("   3. Ajustar hiperpar√°metros si es necesario")
    print("   4. Considerar probar modelos adicionales (XGBoost, etc.)")
    
    print("\n" + "="*70)
    print("  ¬°Gracias por usar el proyecto de Detecci√≥n de Fraude!")
    print("="*70 + "\n")


def main():
    """
    Funci√≥n principal con argumentos de l√≠nea de comandos
    """
    parser = argparse.ArgumentParser(
        description='Pipeline de Detecci√≥n de Fraude con Tarjetas de Cr√©dito',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  python main.py                              # Ejecutar pipeline completo
  python main.py --skip-eda                   # Omitir an√°lisis exploratorio
  python main.py --skip-training              # Usar modelos ya entrenados
  python main.py --model logistic_regression  # Evaluar modelo espec√≠fico
  python main.py --skip-eda --skip-training   # Solo evaluaci√≥n
        """
    )
    
    parser.add_argument(
        '--skip-eda',
        action='store_true',
        help='Omitir el an√°lisis exploratorio de datos (EDA)'
    )
    
    parser.add_argument(
        '--skip-training',
        action='store_true',
        help='Omitir el entrenamiento de modelos (usar modelos guardados)'
    )
    
    parser.add_argument(
        '--model',
        type=str,
        default='random_forest',
        choices=['logistic_regression', 'random_forest'],
        help='Modelo a evaluar en el test set (default: random_forest)'
    )
    
    args = parser.parse_args()
    
    # Ejecutar pipeline
    run_full_pipeline(
        skip_eda=args.skip_eda,
        skip_training=args.skip_training,
        model_name=args.model
    )


if __name__ == "__main__":
    main()